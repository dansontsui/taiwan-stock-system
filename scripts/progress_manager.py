#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è³‡æ–™æ”¶é›†é€²åº¦ç®¡ç†å™¨ - æ”¯æ´æ–·é»çºŒå‚³åŠŸèƒ½
æä¾›é€²åº¦è¨˜éŒ„ã€è¼‰å…¥ã€æ›´æ–°ã€é‡ç½®ç­‰åŠŸèƒ½
"""

import os
import json
import sqlite3
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Set, Any
from dataclasses import dataclass, asdict
from enum import Enum

class TaskType(Enum):
    """ä»»å‹™é¡å‹æšèˆ‰"""
    STOCK_PRICES = "stock_prices"
    MONTHLY_REVENUE = "monthly_revenue"
    FINANCIAL_STATEMENTS = "financial_statements"
    BALANCE_SHEETS = "balance_sheets"
    CASH_FLOWS = "cash_flows"
    DIVIDEND_RESULTS = "dividend_results"
    DIVIDEND_POLICIES = "dividend_policies"
    COMPREHENSIVE = "comprehensive"
    CUSTOM = "custom"

class TaskStatus(Enum):
    """ä»»å‹™ç‹€æ…‹æšèˆ‰"""
    NOT_STARTED = "not_started"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"
    SKIPPED = "skipped"

@dataclass
class StockProgress:
    """å–®ä¸€è‚¡ç¥¨çš„é€²åº¦è¨˜éŒ„"""
    stock_id: str
    stock_name: str
    status: TaskStatus
    completed_datasets: List[str]  # å·²å®Œæˆçš„è³‡æ–™é›†
    failed_datasets: List[str]     # å¤±æ•—çš„è³‡æ–™é›†
    last_updated: str
    retry_count: int = 0
    error_message: Optional[str] = None

@dataclass
class TaskProgress:
    """ä»»å‹™é€²åº¦è¨˜éŒ„"""
    task_id: str
    task_type: TaskType
    task_name: str
    status: TaskStatus
    total_stocks: int
    completed_stocks: int
    failed_stocks: int
    skipped_stocks: int
    start_time: str
    last_updated: str
    end_time: Optional[str] = None
    parameters: Dict[str, Any] = None  # ä»»å‹™åƒæ•¸ï¼ˆæ—¥æœŸç¯„åœã€æ‰¹æ¬¡å¤§å°ç­‰ï¼‰
    stock_progress: Dict[str, StockProgress] = None  # è‚¡ç¥¨é€²åº¦è©³æƒ…

    def __post_init__(self):
        if self.stock_progress is None:
            self.stock_progress = {}
        if self.parameters is None:
            self.parameters = {}

class ProgressManager:
    """é€²åº¦ç®¡ç†å™¨"""
    
    def __init__(self, progress_dir: str = "data/progress"):
        """
        åˆå§‹åŒ–é€²åº¦ç®¡ç†å™¨

        Args:
            progress_dir: é€²åº¦æª”æ¡ˆå„²å­˜ç›®éŒ„
        """
        self.progress_dir = Path(progress_dir)
        self.progress_dir.mkdir(parents=True, exist_ok=True)

        # é€²åº¦æª”æ¡ˆè·¯å¾‘
        self.progress_file = self.progress_dir / "collection_progress.json"
        self.backup_dir = self.progress_dir / "backups"
        self.backup_dir.mkdir(exist_ok=True)

        # å‚™ä»½æ§åˆ¶
        self.last_backup_time = None
        self.backup_interval_minutes = 30  # 30åˆ†é˜å‚™ä»½ä¸€æ¬¡
        self.max_backups = 10  # æœ€å¤šä¿ç•™10å€‹å‚™ä»½æª”æ¡ˆ
    
    def _generate_task_id(self, task_type: TaskType, parameters: Dict[str, Any] = None) -> str:
        """ç”Ÿæˆä»»å‹™IDï¼ˆç°¡åŒ–ç‰ˆï¼Œé¿å…éé•·çš„IDï¼‰"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # ç°¡åŒ–åƒæ•¸è™•ç†ï¼ŒåªåŒ…å«é—œéµåƒæ•¸
        if parameters:
            key_params = []
            if parameters.get('stock_id'):
                key_params.append(f"stock_{parameters['stock_id']}")
            if parameters.get('test_mode'):
                key_params.append("test")

            if key_params:
                param_str = "_".join(key_params)
                return f"{task_type.value}_{param_str}_{timestamp}"

        return f"{task_type.value}_{timestamp}"
    
    def create_task(self, 
                   task_type: TaskType, 
                   task_name: str,
                   stock_list: List[Dict[str, str]],
                   parameters: Dict[str, Any] = None) -> str:
        """
        å‰µå»ºæ–°ä»»å‹™
        
        Args:
            task_type: ä»»å‹™é¡å‹
            task_name: ä»»å‹™åç¨±
            stock_list: è‚¡ç¥¨æ¸…å–® [{'stock_id': '2330', 'stock_name': 'å°ç©é›»'}, ...]
            parameters: ä»»å‹™åƒæ•¸
            
        Returns:
            ä»»å‹™ID
        """
        task_id = self._generate_task_id(task_type, parameters)
        
        # å‰µå»ºä»»å‹™é€²åº¦è¨˜éŒ„
        task_progress = TaskProgress(
            task_id=task_id,
            task_type=task_type,
            task_name=task_name,
            status=TaskStatus.NOT_STARTED,
            total_stocks=len(stock_list),
            completed_stocks=0,
            failed_stocks=0,
            skipped_stocks=0,
            start_time=datetime.now().isoformat(),
            last_updated=datetime.now().isoformat(),
            parameters=parameters or {}
        )
        
        # åˆå§‹åŒ–è‚¡ç¥¨é€²åº¦
        for stock in stock_list:
            stock_progress = StockProgress(
                stock_id=stock['stock_id'],
                stock_name=stock['stock_name'],
                status=TaskStatus.NOT_STARTED,
                completed_datasets=[],
                failed_datasets=[],
                last_updated=datetime.now().isoformat()
            )
            task_progress.stock_progress[stock['stock_id']] = stock_progress
        
        # å„²å­˜é€²åº¦
        try:
            self._save_task_progress(task_progress)
            print(f"âœ… å‰µå»ºä»»å‹™: {task_id}")
            print(f"   ä»»å‹™é¡å‹: {task_type.value}")
            print(f"   è‚¡ç¥¨æ•¸é‡: {len(stock_list)}")
        except Exception as e:
            print(f"âš ï¸ ä»»å‹™å„²å­˜å¤±æ•—: {e}")
            print("ğŸ“ ä»»å‹™å°‡åœ¨è¨˜æ†¶é«”ä¸­ç¹¼çºŒï¼Œä½†ä¸æœƒæŒä¹…åŒ–")

        return task_id
    
    def load_task_progress(self, task_id: str) -> Optional[TaskProgress]:
        """è¼‰å…¥ä»»å‹™é€²åº¦"""
        try:
            if not self.progress_file.exists():
                return None

            with open(self.progress_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except KeyboardInterrupt:
            print("\nâš ï¸ ä½¿ç”¨è€…ä¸­æ–·è¼‰å…¥é€²åº¦")
            raise  # é‡æ–°æ‹‹å‡ºä¸­æ–·ä¿¡è™Ÿ
            
            if task_id not in data.get('tasks', {}):
                return None
            
            task_data = data['tasks'][task_id]
            
            # é‡å»ºTaskProgressç‰©ä»¶
            task_progress = TaskProgress(
                task_id=task_data['task_id'],
                task_type=TaskType(task_data['task_type']),
                task_name=task_data['task_name'],
                status=TaskStatus(task_data['status']),
                total_stocks=task_data['total_stocks'],
                completed_stocks=task_data['completed_stocks'],
                failed_stocks=task_data['failed_stocks'],
                skipped_stocks=task_data['skipped_stocks'],
                start_time=task_data['start_time'],
                last_updated=task_data['last_updated'],
                end_time=task_data.get('end_time'),
                parameters=task_data.get('parameters', {})
            )
            
            # é‡å»ºè‚¡ç¥¨é€²åº¦
            for stock_id, stock_data in task_data.get('stock_progress', {}).items():
                stock_progress = StockProgress(
                    stock_id=stock_data['stock_id'],
                    stock_name=stock_data['stock_name'],
                    status=TaskStatus(stock_data['status']),
                    completed_datasets=stock_data['completed_datasets'],
                    failed_datasets=stock_data['failed_datasets'],
                    last_updated=stock_data['last_updated'],
                    retry_count=stock_data.get('retry_count', 0),
                    error_message=stock_data.get('error_message')
                )
                task_progress.stock_progress[stock_id] = stock_progress
            
            return task_progress
            
        except Exception as e:
            print(f"âŒ è¼‰å…¥ä»»å‹™é€²åº¦å¤±æ•—: {e}")
            return None
    
    def _save_task_progress(self, task_progress: TaskProgress):
        """å„²å­˜ä»»å‹™é€²åº¦"""
        try:
            # è¼‰å…¥ç¾æœ‰é€²åº¦è³‡æ–™
            data = {'tasks': {}, 'last_updated': datetime.now().isoformat()}
            if self.progress_file.exists():
                try:
                    with open(self.progress_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                except json.JSONDecodeError as e:
                    print(f"âš ï¸ é€²åº¦æª”æ¡ˆæå£: {e}")
                    print("ğŸ”§ å˜—è©¦å¾å‚™ä»½æ¢å¾©...")

                    # å˜—è©¦å¾æœ€æ–°çš„å‚™ä»½æ¢å¾©
                    backup_restored = self._restore_from_backup()
                    if backup_restored:
                        try:
                            with open(self.progress_file, 'r', encoding='utf-8') as f:
                                data = json.load(f)
                            print("âœ… å¾å‚™ä»½æˆåŠŸæ¢å¾©é€²åº¦æª”æ¡ˆ")
                        except:
                            print("âŒ å‚™ä»½æª”æ¡ˆä¹Ÿæå£ï¼Œä½¿ç”¨ç©ºç™½é€²åº¦")
                            data = {'tasks': {}, 'last_updated': datetime.now().isoformat()}
                    else:
                        print("âŒ ç„¡æ³•å¾å‚™ä»½æ¢å¾©ï¼Œä½¿ç”¨ç©ºç™½é€²åº¦")
                        data = {'tasks': {}, 'last_updated': datetime.now().isoformat()}
            
            # è½‰æ›ç‚ºå¯åºåˆ—åŒ–çš„æ ¼å¼
            task_data = asdict(task_progress)
            task_data['task_type'] = task_progress.task_type.value
            task_data['status'] = task_progress.status.value
            
            # è½‰æ›è‚¡ç¥¨é€²åº¦
            for stock_id, stock_progress in task_data['stock_progress'].items():
                stock_progress['status'] = stock_progress['status'].value
            
            # æ›´æ–°ä»»å‹™è³‡æ–™
            data['tasks'][task_progress.task_id] = task_data
            data['last_updated'] = datetime.now().isoformat()
            
            # æ™ºèƒ½å‚™ä»½ï¼šåªåœ¨éœ€è¦æ™‚å‚™ä»½
            if self.progress_file.exists() and self._should_backup():
                self._create_backup()

            # ä½¿ç”¨åŸå­å¯«å…¥é¿å…æª”æ¡ˆæå£
            temp_file = self.progress_file.with_suffix('.tmp')
            try:
                # å…ˆå¯«å…¥è‡¨æ™‚æª”æ¡ˆ
                with open(temp_file, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)

                # é©—è­‰å¯«å…¥çš„æª”æ¡ˆæ˜¯å¦æœ‰æ•ˆ
                with open(temp_file, 'r', encoding='utf-8') as f:
                    json.load(f)  # é©—è­‰JSONæ ¼å¼

                # å¦‚æœé©—è­‰æˆåŠŸï¼ŒåŸå­æ€§åœ°æ›¿æ›åŸæª”æ¡ˆ
                if os.name == 'nt':  # Windows
                    if self.progress_file.exists():
                        self.progress_file.unlink()
                    temp_file.rename(self.progress_file)
                else:  # Unix/Linux/macOS
                    temp_file.rename(self.progress_file)

            except Exception as e:
                # å¦‚æœå¯«å…¥å¤±æ•—ï¼Œæ¸…ç†è‡¨æ™‚æª”æ¡ˆ
                if temp_file.exists():
                    temp_file.unlink()
                raise e
                
        except Exception as e:
            print(f"âŒ å„²å­˜ä»»å‹™é€²åº¦å¤±æ•—: {e}")
            raise

    def _should_backup(self):
        """åˆ¤æ–·æ˜¯å¦éœ€è¦å‚™ä»½"""
        if self.last_backup_time is None:
            return True

        # æª¢æŸ¥æ˜¯å¦è¶…éå‚™ä»½é–“éš”
        elapsed_minutes = (datetime.now() - self.last_backup_time).total_seconds() / 60
        return elapsed_minutes >= self.backup_interval_minutes

    def _create_backup(self):
        """å‰µå»ºå‚™ä»½æª”æ¡ˆ"""
        try:
            backup_file = self.backup_dir / f"progress_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

            # ä½¿ç”¨copyè€Œä¸æ˜¯renameï¼Œé¿å…Windowsæª”æ¡ˆé–å®šå•é¡Œ
            import shutil
            shutil.copy2(self.progress_file, backup_file)

            # æ›´æ–°æœ€å¾Œå‚™ä»½æ™‚é–“
            self.last_backup_time = datetime.now()

            # æ¸…ç†èˆŠå‚™ä»½æª”æ¡ˆ
            self._cleanup_old_backups()

            print(f"ğŸ“ å‰µå»ºå‚™ä»½: {backup_file.name}")

        except Exception as e:
            print(f"âš ï¸ å‚™ä»½å¤±æ•—: {e}")

    def _cleanup_old_backups(self):
        """æ¸…ç†èˆŠçš„å‚™ä»½æª”æ¡ˆ"""
        try:
            # ç²å–æ‰€æœ‰å‚™ä»½æª”æ¡ˆï¼ŒæŒ‰æ™‚é–“æ’åº
            backup_files = list(self.backup_dir.glob("progress_backup_*.json"))
            backup_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)

            # åˆªé™¤è¶…éé™åˆ¶çš„èˆŠå‚™ä»½
            if len(backup_files) > self.max_backups:
                for old_backup in backup_files[self.max_backups:]:
                    old_backup.unlink()
                    print(f"ğŸ—‘ï¸ æ¸…ç†èˆŠå‚™ä»½: {old_backup.name}")

        except Exception as e:
            print(f"âš ï¸ æ¸…ç†å‚™ä»½å¤±æ•—: {e}")

    def _restore_from_backup(self):
        """å¾å‚™ä»½æ¢å¾©é€²åº¦æª”æ¡ˆ"""
        try:
            # ç²å–æ‰€æœ‰å‚™ä»½æª”æ¡ˆï¼ŒæŒ‰æ™‚é–“æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            backup_files = list(self.backup_dir.glob("progress_backup_*.json"))
            backup_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)

            if not backup_files:
                print("âŒ æ²’æœ‰æ‰¾åˆ°å‚™ä»½æª”æ¡ˆ")
                return False

            # å˜—è©¦å¾æœ€æ–°çš„å‚™ä»½æ¢å¾©
            for backup_file in backup_files:
                try:
                    print(f"ğŸ”„ å˜—è©¦å¾å‚™ä»½æ¢å¾©: {backup_file.name}")

                    # é©—è­‰å‚™ä»½æª”æ¡ˆæ˜¯å¦æœ‰æ•ˆ
                    with open(backup_file, 'r', encoding='utf-8') as f:
                        json.load(f)  # é©—è­‰JSONæ ¼å¼

                    # å¦‚æœé©—è­‰æˆåŠŸï¼Œè¤‡è£½åˆ°ä¸»æª”æ¡ˆ
                    import shutil
                    shutil.copy2(backup_file, self.progress_file)
                    print(f"âœ… æˆåŠŸå¾å‚™ä»½æ¢å¾©: {backup_file.name}")
                    return True

                except json.JSONDecodeError:
                    print(f"âš ï¸ å‚™ä»½æª”æ¡ˆä¹Ÿæå£: {backup_file.name}")
                    continue
                except Exception as e:
                    print(f"âš ï¸ æ¢å¾©å‚™ä»½å¤±æ•—: {backup_file.name}, éŒ¯èª¤: {e}")
                    continue

            print("âŒ æ‰€æœ‰å‚™ä»½æª”æ¡ˆéƒ½ç„¡æ³•ä½¿ç”¨")
            return False

        except Exception as e:
            print(f"âŒ å‚™ä»½æ¢å¾©éç¨‹å¤±æ•—: {e}")
            return False

    def _find_task_by_fuzzy_match(self, target_task_id: str, stock_id: str = None) -> Optional[TaskProgress]:
        """é€šéæ¨¡ç³ŠåŒ¹é…æŸ¥æ‰¾ä»»å‹™"""
        try:
            if not self.progress_file.exists():
                return None

            with open(self.progress_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # å˜—è©¦ä¸åŒçš„åŒ¹é…ç­–ç•¥
            for task_id, task_data in data.get('tasks', {}).items():
                # ç­–ç•¥1ï¼šæª¢æŸ¥æ˜¯å¦åŒ…å«ç›¸åŒçš„è‚¡ç¥¨ID
                if stock_id and stock_id in task_data.get('stock_progress', {}):
                    # æª¢æŸ¥ä»»å‹™é¡å‹æ˜¯å¦åŒ¹é…
                    if target_task_id.startswith(task_data.get('task_type', '')):
                        print(f"âœ… é€šéè‚¡ç¥¨IDåŒ¹é…æ‰¾åˆ°ä»»å‹™: {task_id}")
                        # ç›´æ¥æ§‹é€  TaskProgress å°è±¡è¿”å›
                        return TaskProgress(
                            task_id=task_id,
                            task_type=TaskType(task_data.get('task_type', 'comprehensive')),
                            task_name=task_data.get('task_name', ''),
                            status=TaskStatus(task_data.get('status', 'not_started')),
                            total_stocks=task_data.get('total_stocks', 0),
                            completed_stocks=task_data.get('completed_stocks', 0),
                            failed_stocks=task_data.get('failed_stocks', 0),
                            skipped_stocks=task_data.get('skipped_stocks', 0),
                            start_time=task_data.get('start_time', ''),
                            last_updated=task_data.get('last_updated', ''),
                            parameters=task_data.get('parameters', {}),
                            stock_progress={
                                sid: StockProgress(
                                    stock_id=sid,
                                    stock_name=sdata.get('stock_name', ''),
                                    status=TaskStatus(sdata.get('status', 'not_started')),
                                    completed_datasets=sdata.get('completed_datasets', []),
                                    failed_datasets=sdata.get('failed_datasets', []),
                                    last_updated=sdata.get('last_updated', '')
                                ) for sid, sdata in task_data.get('stock_progress', {}).items()
                            }
                        )

                # ç­–ç•¥2ï¼šæª¢æŸ¥ä»»å‹™IDçš„å‰ç¶´æ˜¯å¦åŒ¹é…
                target_prefix = target_task_id.split('_')[0]  # å–ä»»å‹™é¡å‹éƒ¨åˆ†
                task_prefix = task_id.split('_')[0]
                if target_prefix == task_prefix:
                    # é€²ä¸€æ­¥æª¢æŸ¥æ˜¯å¦ç‚ºæœ€è¿‘çš„ä»»å‹™
                    task_time = task_data.get('created_at', '')
                    if task_time:  # å¦‚æœæ˜¯æœ€è¿‘å‰µå»ºçš„ä»»å‹™
                        print(f"âœ… é€šéé¡å‹åŒ¹é…æ‰¾åˆ°ä»»å‹™: {task_id}")
                        return self.load_task_progress(task_id)

            return None

        except Exception as e:
            print(f"âš ï¸ æ¨¡ç³ŠåŒ¹é…å¤±æ•—: {e}")
            return None
    
    def update_stock_progress(self,
                            task_id: str,
                            stock_id: str,
                            status: TaskStatus,
                            completed_datasets: List[str] = None,
                            failed_datasets: List[str] = None,
                            error_message: str = None):
        """æ›´æ–°è‚¡ç¥¨é€²åº¦"""
        try:
            task_progress = self.load_task_progress(task_id)
            if not task_progress:
                # å˜—è©¦æ¨¡ç³ŠåŒ¹é…ä»»å‹™ID
                task_progress = self._find_task_by_fuzzy_match(task_id, stock_id)
                if not task_progress:
                    print(f"âš ï¸ æ‰¾ä¸åˆ°ä»»å‹™: {task_id[:50]}...")
                    return
        except Exception as e:
            print(f"âš ï¸ è¼‰å…¥ä»»å‹™é€²åº¦å¤±æ•—: {e}")
            return
        
        if stock_id not in task_progress.stock_progress:
            print(f"âŒ æ‰¾ä¸åˆ°è‚¡ç¥¨: {stock_id}")
            return
        
        # æ›´æ–°è‚¡ç¥¨é€²åº¦
        stock_progress = task_progress.stock_progress[stock_id]
        old_status = stock_progress.status
        stock_progress.status = status
        stock_progress.last_updated = datetime.now().isoformat()
        
        if completed_datasets:
            stock_progress.completed_datasets.extend(completed_datasets)
            stock_progress.completed_datasets = list(set(stock_progress.completed_datasets))
        
        if failed_datasets:
            stock_progress.failed_datasets.extend(failed_datasets)
            stock_progress.failed_datasets = list(set(stock_progress.failed_datasets))
        
        if error_message:
            stock_progress.error_message = error_message
            stock_progress.retry_count += 1
        
        # æ›´æ–°ä»»å‹™çµ±è¨ˆ
        if old_status != status:
            if old_status == TaskStatus.COMPLETED:
                task_progress.completed_stocks -= 1
            elif old_status == TaskStatus.FAILED:
                task_progress.failed_stocks -= 1
            elif old_status == TaskStatus.SKIPPED:
                task_progress.skipped_stocks -= 1
            
            if status == TaskStatus.COMPLETED:
                task_progress.completed_stocks += 1
            elif status == TaskStatus.FAILED:
                task_progress.failed_stocks += 1
            elif status == TaskStatus.SKIPPED:
                task_progress.skipped_stocks += 1
        
        # æ›´æ–°ä»»å‹™ç‹€æ…‹
        task_progress.last_updated = datetime.now().isoformat()
        if task_progress.completed_stocks + task_progress.failed_stocks + task_progress.skipped_stocks >= task_progress.total_stocks:
            task_progress.status = TaskStatus.COMPLETED
            task_progress.end_time = datetime.now().isoformat()
        elif task_progress.completed_stocks > 0 or task_progress.failed_stocks > 0:
            task_progress.status = TaskStatus.IN_PROGRESS
        
        # å„²å­˜é€²åº¦
        self._save_task_progress(task_progress)
    
    def get_pending_stocks(self, task_id: str) -> List[Dict[str, str]]:
        """ç²å–å¾…è™•ç†çš„è‚¡ç¥¨æ¸…å–®"""
        task_progress = self.load_task_progress(task_id)
        if not task_progress:
            return []

        pending_stocks = []
        for stock_id, stock_progress in task_progress.stock_progress.items():
            # åŒ…å«æœªé–‹å§‹ã€å¤±æ•—ã€å’Œé€²è¡Œä¸­ä½†æœªå®Œæˆçš„è‚¡ç¥¨
            if stock_progress.status in [TaskStatus.NOT_STARTED, TaskStatus.FAILED, TaskStatus.IN_PROGRESS]:
                pending_stocks.append({
                    'stock_id': stock_progress.stock_id,
                    'stock_name': stock_progress.stock_name
                })

        return pending_stocks
    
    def reset_task(self, task_id: str):
        """é‡ç½®ä»»å‹™é€²åº¦"""
        task_progress = self.load_task_progress(task_id)
        if not task_progress:
            print(f"âŒ æ‰¾ä¸åˆ°ä»»å‹™: {task_id}")
            return
        
        # é‡ç½®ä»»å‹™ç‹€æ…‹
        task_progress.status = TaskStatus.NOT_STARTED
        task_progress.completed_stocks = 0
        task_progress.failed_stocks = 0
        task_progress.skipped_stocks = 0
        task_progress.start_time = datetime.now().isoformat()
        task_progress.last_updated = datetime.now().isoformat()
        task_progress.end_time = None
        
        # é‡ç½®æ‰€æœ‰è‚¡ç¥¨é€²åº¦
        for stock_progress in task_progress.stock_progress.values():
            stock_progress.status = TaskStatus.NOT_STARTED
            stock_progress.completed_datasets = []
            stock_progress.failed_datasets = []
            stock_progress.last_updated = datetime.now().isoformat()
            stock_progress.retry_count = 0
            stock_progress.error_message = None
        
        # å„²å­˜é€²åº¦
        self._save_task_progress(task_progress)
        print(f"âœ… ä»»å‹™ {task_id} å·²é‡ç½®")
    
    def list_tasks(self) -> List[Dict[str, Any]]:
        """åˆ—å‡ºæ‰€æœ‰ä»»å‹™"""
        try:
            if not self.progress_file.exists():
                return []
            
            with open(self.progress_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            tasks = []
            for task_id, task_data in data.get('tasks', {}).items():
                tasks.append({
                    'task_id': task_id,
                    'task_type': task_data['task_type'],
                    'task_name': task_data['task_name'],
                    'status': task_data['status'],
                    'total_stocks': task_data['total_stocks'],
                    'completed_stocks': task_data['completed_stocks'],
                    'failed_stocks': task_data['failed_stocks'],
                    'start_time': task_data['start_time'],
                    'last_updated': task_data['last_updated']
                })
            
            return sorted(tasks, key=lambda x: x['last_updated'], reverse=True)
            
        except Exception as e:
            print(f"âŒ åˆ—å‡ºä»»å‹™å¤±æ•—: {e}")
            return []
    
    def delete_task(self, task_id: str):
        """åˆªé™¤ä»»å‹™"""
        try:
            if not self.progress_file.exists():
                print(f"âŒ æ‰¾ä¸åˆ°é€²åº¦æª”æ¡ˆ")
                return
            
            with open(self.progress_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if task_id in data.get('tasks', {}):
                del data['tasks'][task_id]
                data['last_updated'] = datetime.now().isoformat()
                
                with open(self.progress_file, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
                
                print(f"âœ… ä»»å‹™ {task_id} å·²åˆªé™¤")
            else:
                print(f"âŒ æ‰¾ä¸åˆ°ä»»å‹™: {task_id}")
                
        except Exception as e:
            print(f"âŒ åˆªé™¤ä»»å‹™å¤±æ•—: {e}")
