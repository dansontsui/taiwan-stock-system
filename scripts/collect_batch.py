#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†æ‰¹æ”¶é›†è‚¡ç¥¨è³‡æ–™è…³æœ¬ - è‡ªå‹•è™•ç†APIé™åˆ¶
"""

import sys
import os
import time
from datetime import datetime, timedelta
import argparse

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config import Config
from app.utils.simple_database import SimpleDatabaseManager
from app.services.data_collector import FinMindDataCollector
from loguru import logger

def calculate_wait_time(start_time):
    """è¨ˆç®—æ™ºèƒ½ç­‰å¾…æ™‚é–“"""
    current_time = datetime.now()
    elapsed_minutes = (current_time - start_time).total_seconds() / 60

    # APIé™åˆ¶æ˜¯æ¯å°æ™‚é‡ç½®ï¼Œæ‰€ä»¥è¨ˆç®—åˆ°ä¸‹ä¸€å€‹å°æ™‚çš„æ™‚é–“
    minutes_in_hour = current_time.minute
    seconds_in_minute = current_time.second

    # è¨ˆç®—åˆ°ä¸‹ä¸€å€‹å°æ™‚é‚„éœ€è¦å¤šå°‘æ™‚é–“
    minutes_to_next_hour = 60 - minutes_in_hour
    seconds_to_next_hour = (minutes_to_next_hour * 60) - seconds_in_minute

    # åŠ ä¸Š5åˆ†é˜ç·©è¡æ™‚é–“
    total_wait_seconds = seconds_to_next_hour + (5 * 60)

    return total_wait_seconds, elapsed_minutes

def wait_for_api_reset(start_time=None):
    """æ™ºèƒ½ç­‰å¾…APIé™åˆ¶é‡ç½®"""
    if start_time is None:
        start_time = datetime.now()

    wait_seconds, elapsed_minutes = calculate_wait_time(start_time)

    print("\n" + "="*60)
    print("â° APIè«‹æ±‚é™åˆ¶å·²é”ä¸Šé™ï¼Œæ™ºèƒ½ç­‰å¾…é‡ç½®...")
    print("="*60)
    print(f"ğŸ“Š æœ¬è¼ªå·²é‹è¡Œ: {elapsed_minutes:.1f} åˆ†é˜")
    print(f"â³ é è¨ˆç­‰å¾…: {wait_seconds/60:.1f} åˆ†é˜")
    print("="*60)

    # é¡¯ç¤ºå€’è¨ˆæ™‚
    for remaining in range(int(wait_seconds), 0, -60):
        hours = remaining // 3600
        minutes = (remaining % 3600) // 60
        current_time = datetime.now().strftime("%H:%M:%S")
        print(f"\râ³ [{current_time}] å‰©é¤˜ç­‰å¾…æ™‚é–“: {hours:02d}:{minutes:02d}:00", end="", flush=True)
        time.sleep(60)

    print(f"\nâœ… [{datetime.now().strftime('%H:%M:%S')}] ç­‰å¾…å®Œæˆï¼Œç¹¼çºŒæ”¶é›†è³‡æ–™...")
    print("="*60)

def collect_batch_with_retry(collector, stock_batch, start_date, end_date, batch_start_time, max_retries=3):
    """æ”¶é›†ä¸€æ‰¹è‚¡ç¥¨è³‡æ–™ï¼Œæ”¯æ´é‡è©¦"""
    for attempt in range(max_retries):
        try:
            print(f"\nğŸ“Š æ”¶é›†æ‰¹æ¬¡è³‡æ–™ (ç¬¬ {attempt + 1} æ¬¡å˜—è©¦)...")
            collected_data = collector.collect_batch_data(
                stock_list=stock_batch,
                start_date=start_date,
                end_date=end_date,
                batch_size=10
            )
            return collected_data
            
        except Exception as e:
            error_msg = str(e)
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºAPIé™åˆ¶éŒ¯èª¤
            if "402" in error_msg or "Payment Required" in error_msg:
                print(f"\nâš ï¸  é‡åˆ°APIé™åˆ¶éŒ¯èª¤: {error_msg}")
                if attempt < max_retries - 1:
                    wait_for_api_reset(batch_start_time)
                    # é‡ç½®é–‹å§‹æ™‚é–“ç‚ºç­‰å¾…å¾Œçš„æ™‚é–“
                    batch_start_time = datetime.now()
                    continue
                else:
                    raise Exception("APIé™åˆ¶éŒ¯èª¤ï¼Œå·²é”æœ€å¤§é‡è©¦æ¬¡æ•¸")
            
            # å…¶ä»–éŒ¯èª¤
            elif attempt < max_retries - 1:
                print(f"âš ï¸  æ”¶é›†å¤±æ•— (ç¬¬ {attempt + 1} æ¬¡): {error_msg}")
                print("ç­‰å¾…30ç§’å¾Œé‡è©¦...")
                time.sleep(30)
                continue
            else:
                raise e
    
    return None

def check_existing_data(db_manager, stock_id, start_date, end_date):
    """æª¢æŸ¥è‚¡ç¥¨æ˜¯å¦å·²æœ‰å®Œæ•´è³‡æ–™"""
    try:
        conn = db_manager.get_connection()
        cursor = conn.cursor()

        # æª¢æŸ¥æ˜¯å¦æœ‰è©²è‚¡ç¥¨çš„è³‡æ–™
        cursor.execute('''
            SELECT COUNT(*), MIN(date), MAX(date)
            FROM stock_prices
            WHERE stock_id = ?
        ''', (stock_id,))

        result = cursor.fetchone()
        conn.close()

        if not result or result[0] == 0:
            return False, "ç„¡è³‡æ–™"

        count, min_date, max_date = result

        # æª¢æŸ¥è³‡æ–™ç¯„åœæ˜¯å¦æ¶µè“‹éœ€æ±‚ç¯„åœ
        if min_date <= start_date and max_date >= end_date:
            return True, f"å·²æœ‰å®Œæ•´è³‡æ–™ ({count:,}ç­†, {min_date}~{max_date})"
        else:
            return False, f"è³‡æ–™ä¸å®Œæ•´ ({count:,}ç­†, {min_date}~{max_date})"

    except Exception as e:
        return False, f"æª¢æŸ¥å¤±æ•—: {e}"

def collect_main_stocks_batch(start_date=None, end_date=None, batch_size=200, skip_existing=True):
    """åˆ†æ‰¹æ”¶é›†ä¸»è¦è‚¡ç¥¨è³‡æ–™"""
    
    # è¨­å®šé è¨­æ—¥æœŸ
    if not start_date:
        start_date = Config.DATA_START_DATE
    if not end_date:
        end_date = Config.DATA_END_DATE
    
    print("="*60)
    print("ğŸ“ˆ å°è‚¡ä¸»è¦è‚¡ç¥¨åˆ†æ‰¹æ”¶é›†ç³»çµ±")
    print("="*60)
    print(f"è³‡æ–™æœŸé–“: {start_date} ~ {end_date}")
    print(f"æ‰¹æ¬¡å¤§å°: {batch_size} æª”")
    print("="*60)
    
    # åˆå§‹åŒ–
    db_manager = SimpleDatabaseManager(Config.DATABASE_PATH)
    collector = FinMindDataCollector(
        api_url=Config.FINMIND_API_URL,
        api_token=Config.FINMIND_API_TOKEN
    )
    
    try:
        # 1. å–å¾—å®Œæ•´è‚¡ç¥¨æ¸…å–®
        print("\n1. å–å¾—è‚¡ç¥¨æ¸…å–®...")
        stock_list = collector.get_stock_list(use_full_list=True)
        
        # ç¯©é¸ä¸»è¦è‚¡ç¥¨ï¼šä¸Šå¸‚ã€ä¸Šæ«ƒã€00é–‹é ­ETF
        main_stocks = [s for s in stock_list if (
            s['market'] in ['TWSE', 'TPEX'] and (
                # æ’é™¤01é–‹é ­çš„ç‰¹æ®Šè‚¡ç¥¨ï¼ˆæ¬Šè­‰ç­‰ï¼‰
                not s['stock_id'].startswith('01') and
                not s['stock_id'].startswith('02') and
                # ETFåªä¿ç•™00é–‹é ­çš„
                (not s['is_etf'] or s['stock_id'].startswith('00'))
            )
        )]
        
        print(f"   å®Œæ•´æ¸…å–®: {len(stock_list)} æª”")
        print(f"   ç¯©é¸å¾Œ: {len(main_stocks)} æª”")
        
        # çµ±è¨ˆåˆ†å¸ƒ
        twse_count = len([s for s in main_stocks if s['market'] == 'TWSE' and not s['is_etf']])
        tpex_count = len([s for s in main_stocks if s['market'] == 'TPEX' and not s['is_etf']])
        etf_count = len([s for s in main_stocks if s['is_etf']])
        
        print(f"   ä¸Šå¸‚è‚¡ç¥¨: {twse_count} æª”")
        print(f"   ä¸Šæ«ƒè‚¡ç¥¨: {tpex_count} æª”")
        print(f"   00é–‹é ­ETF: {etf_count} æª”")

        # 2. æª¢æŸ¥å·²æœ‰è³‡æ–™ï¼Œéæ¿¾éœ€è¦æ”¶é›†çš„è‚¡ç¥¨ (é è¨­å•Ÿç”¨)
        if skip_existing:
            print(f"\n2. æª¢æŸ¥å·²æœ‰è³‡æ–™...")
            stocks_to_collect = []
            stocks_skipped = []

            for i, stock in enumerate(main_stocks):
                if i % 100 == 0:
                    print(f"   æª¢æŸ¥é€²åº¦: {i}/{len(main_stocks)}")

                has_data, reason = check_existing_data(db_manager, stock['stock_id'], start_date, end_date)

                if has_data:
                    stocks_skipped.append({
                        'stock': stock,
                        'reason': reason
                    })
                else:
                    stocks_to_collect.append(stock)
        else:
            print(f"\n2. è·³éè³‡æ–™æª¢æŸ¥ (--no-skip å·²å•Ÿç”¨)")
            stocks_to_collect = main_stocks
            stocks_skipped = []

        print(f"   æª¢æŸ¥å®Œæˆ:")
        print(f"   éœ€è¦æ”¶é›†: {len(stocks_to_collect)} æª”")
        print(f"   è·³éæ”¶é›†: {len(stocks_skipped)} æª”")

        if len(stocks_skipped) > 0:
            print(f"\n   è·³éçš„è‚¡ç¥¨ç¯„ä¾‹ (å‰5æª”):")
            for i, item in enumerate(stocks_skipped[:5]):
                stock = item['stock']
                reason = item['reason']
                print(f"   {i+1}. {stock['stock_id']} {stock['stock_name']} - {reason}")

        if len(stocks_to_collect) == 0:
            print("\nğŸ‰ æ‰€æœ‰è‚¡ç¥¨éƒ½å·²æœ‰å®Œæ•´è³‡æ–™ï¼Œç„¡éœ€æ”¶é›†ï¼")
            return

        # 3. åˆ†æ‰¹è™•ç†éœ€è¦æ”¶é›†çš„è‚¡ç¥¨
        total_batches = (len(stocks_to_collect) + batch_size - 1) // batch_size
        print(f"\n3. é–‹å§‹åˆ†æ‰¹æ”¶é›† (å…± {total_batches} æ‰¹)...")

        successful_batches = 0
        total_collected = 0

        # è¨˜éŒ„æ•´é«”é–‹å§‹æ™‚é–“
        overall_start_time = datetime.now()

        for batch_num in range(total_batches):
            start_idx = batch_num * batch_size
            end_idx = min(start_idx + batch_size, len(stocks_to_collect))
            stock_batch = stocks_to_collect[start_idx:end_idx]
            
            print(f"\n" + "="*50)
            print(f"ğŸ“¦ è™•ç†ç¬¬ {batch_num + 1}/{total_batches} æ‰¹")
            print(f"è‚¡ç¥¨ç¯„åœ: {start_idx + 1} ~ {end_idx}")
            print(f"æ‰¹æ¬¡å¤§å°: {len(stock_batch)} æª”")
            print("="*50)
            
            try:
                # è¨˜éŒ„é€™æ‰¹çš„é–‹å§‹æ™‚é–“
                batch_start_time = datetime.now()

                # æ”¶é›†é€™æ‰¹è‚¡ç¥¨çš„è³‡æ–™
                collected_data = collect_batch_with_retry(
                    collector, stock_batch, start_date, end_date, batch_start_time
                )
                
                if collected_data:
                    # å„²å­˜è³‡æ–™ (é€™è£¡å¯ä»¥åŠ å…¥å„²å­˜é‚è¼¯)
                    batch_collected = len(collected_data.get('stock_prices', {}))
                    total_collected += batch_collected
                    successful_batches += 1
                    
                    print(f"âœ… ç¬¬ {batch_num + 1} æ‰¹å®Œæˆï¼Œæ”¶é›† {batch_collected} æª”è‚¡ç¥¨è³‡æ–™")
                else:
                    print(f"âŒ ç¬¬ {batch_num + 1} æ‰¹å¤±æ•—")
                
                # æ‰¹æ¬¡é–“ç­‰å¾…ï¼Œé¿å…è«‹æ±‚éå¿«
                if batch_num < total_batches - 1:
                    print("â³ ç­‰å¾…10ç§’å¾Œè™•ç†ä¸‹ä¸€æ‰¹...")
                    time.sleep(10)
                    
            except Exception as e:
                print(f"âŒ ç¬¬ {batch_num + 1} æ‰¹è™•ç†å¤±æ•—: {e}")
                
                # è©¢å•æ˜¯å¦ç¹¼çºŒ
                response = input("\næ˜¯å¦ç¹¼çºŒè™•ç†ä¸‹ä¸€æ‰¹ï¼Ÿ(y/n): ").lower()
                if response != 'y':
                    break
        
        # 3. ç¸½çµ
        print("\n" + "="*60)
        print("ğŸ“Š åˆ†æ‰¹æ”¶é›†å®Œæˆçµ±è¨ˆ")
        print("="*60)
        print(f"æˆåŠŸæ‰¹æ¬¡: {successful_batches}/{total_batches}")
        print(f"æ–°æ”¶é›†è‚¡ç¥¨: {total_collected} æª”")
        print(f"è·³éè‚¡ç¥¨: {len(stocks_skipped)} æª”")
        print(f"ç¸½è‚¡ç¥¨æ•¸: {len(main_stocks)} æª”")
        if total_batches > 0:
            print(f"æ”¶é›†æˆåŠŸç‡: {successful_batches/total_batches*100:.1f}%")
        
        if successful_batches == total_batches:
            print("ğŸ‰ æ‰€æœ‰æ‰¹æ¬¡æ”¶é›†å®Œæˆï¼")
        else:
            print("âš ï¸  éƒ¨åˆ†æ‰¹æ¬¡æ”¶é›†å¤±æ•—ï¼Œå¯ç¨å¾Œé‡æ–°åŸ·è¡Œ")
        
    except Exception as e:
        print(f"âŒ ç³»çµ±éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        db_manager.close()

def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(description='åˆ†æ‰¹æ”¶é›†å°è‚¡ä¸»è¦è‚¡ç¥¨è³‡æ–™')
    parser.add_argument('--start-date', help='é–‹å§‹æ—¥æœŸ (YYYY-MM-DD)')
    parser.add_argument('--end-date', help='çµæŸæ—¥æœŸ (YYYY-MM-DD)')
    parser.add_argument('--batch-size', type=int, default=200, help='æ‰¹æ¬¡å¤§å° (é è¨­200æª”)')
    parser.add_argument('--test', action='store_true', help='æ¸¬è©¦æ¨¡å¼ (åªæ”¶é›†è¿‘1å€‹æœˆ)')
    parser.add_argument('--no-skip', action='store_true', help='ä¸è·³éå·²æœ‰è³‡æ–™çš„è‚¡ç¥¨ (é è¨­æœƒè·³é)')
    
    args = parser.parse_args()
    
    # æ¸¬è©¦æ¨¡å¼
    if args.test:
        print("ğŸ§ª æ¸¬è©¦æ¨¡å¼ï¼šåªæ”¶é›†æœ€è¿‘1å€‹æœˆçš„è³‡æ–™")
        start_date = (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d")
        end_date = datetime.now().strftime("%Y-%m-%d")
    else:
        start_date = args.start_date
        end_date = args.end_date
    
    collect_main_stocks_batch(start_date, end_date, args.batch_size, not args.no_skip)

if __name__ == "__main__":
    main()
