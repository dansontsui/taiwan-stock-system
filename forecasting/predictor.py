from __future__ import annotations
import warnings
import numpy as np
import pandas as pd
from typing import Dict, Tuple, Optional
from .features import build_features, train_test_split_time
from .config import cfg
from .param_store import get_best_params, get_best_model


def _safe_import(module_name: str):
    try:
        return __import__(module_name)
    except Exception:
        return None


def mape(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    y_true = np.asarray(y_true, dtype=float)
    y_pred = np.asarray(y_pred, dtype=float)
    mask = y_true != 0
    if mask.sum() == 0:
        return np.inf
    return float(np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100)


def rmse(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    y_true = np.asarray(y_true, dtype=float)
    y_pred = np.asarray(y_pred, dtype=float)
    return float(np.sqrt(np.mean((y_true - y_pred) ** 2)))


def train_prophet(df: pd.DataFrame, stock_id: Optional[str] = None) -> Tuple[object, pd.DataFrame, Dict[str, float]]:
    if not cfg.enable_prophet:
        raise ImportError("Prophet å·²åœç”¨æˆ–æœªå®‰è£")
    prophet = _safe_import("prophet") or _safe_import("fbprophet")
    if prophet is None:
        raise ImportError("Prophet æœªå®‰è£")
    from prophet import Prophet  # type: ignore

    data = df[["date", "y"]].rename(columns={"date": "ds", "y": "y"}).copy()
    # è®€å–å€‹è‚¡æœ€ä½³åƒæ•¸
    best = get_best_params(stock_id, "Prophet") if stock_id else None
    kwargs = dict(weekly_seasonality=False, daily_seasonality=False, yearly_seasonality=True)
    if isinstance(best, dict):
        # æ”¯æ´æ‰€æœ‰ Prophet çš„ä¸»è¦åƒæ•¸
        valid_prophet_params = {
            'changepoint_prior_scale', 'seasonality_prior_scale', 'holidays_prior_scale',
            'seasonality_mode', 'yearly_seasonality', 'weekly_seasonality', 'daily_seasonality',
            'uncertainty_samples', 'mcmc_samples', 'interval_width', 'changepoint_range',
            'n_changepoints', 'holidays', 'growth'
        }
        updated_params = {k: v for k, v in best.items() if k in valid_prophet_params}
        kwargs.update(updated_params)
        if cfg.debug and updated_params:
            print(f"ğŸ”§ Prophet ä½¿ç”¨èª¿æ ¡åƒæ•¸: {updated_params}")
    elif cfg.debug:
        print(f"âš ï¸  Prophet æœªæ‰¾åˆ°èª¿æ ¡åƒæ•¸ï¼Œä½¿ç”¨é è¨­å€¼")
    model = Prophet(**kwargs)
    # è¨­å®šæ›´ç©©å®šçš„å„ªåŒ–å™¨ï¼Œé¿å… macOS æ¬Šé™å•é¡Œ
    try:
        model.fit(data)
    except Exception as e:
        # å¦‚æœé‡åˆ°æ¬Šé™å•é¡Œï¼Œä½¿ç”¨æ›´ä¿å®ˆçš„è¨­å®šé‡è©¦
        if "Operation not permitted" in str(e):
            import logging
            logging.getLogger('cmdstanpy').setLevel(logging.WARNING)
            model = Prophet(uncertainty_samples=0, **kwargs)  # é—œé–‰ä¸ç¢ºå®šæ€§æ¡æ¨£
            model.fit(data)
        else:
            raise e
    future = model.make_future_dataframe(periods=1, freq="MS")
    forecast = model.predict(future)

    # è™•ç† uncertainty_samples=0 çš„æƒ…æ³
    pred_cols = ["ds", "yhat"]
    rename_dict = {"ds": "date", "yhat": "forecast_value"}

    if "yhat_lower" in forecast.columns and "yhat_upper" in forecast.columns:
        pred_cols.extend(["yhat_lower", "yhat_upper"])
        rename_dict.update({"yhat_lower": "lower_bound", "yhat_upper": "upper_bound"})
    else:
        # å¦‚æœæ²’æœ‰ä¸ç¢ºå®šæ€§å€é–“ï¼Œä½¿ç”¨é æ¸¬å€¼ä½œç‚ºä¸Šä¸‹ç•Œ
        forecast["yhat_lower"] = forecast["yhat"]
        forecast["yhat_upper"] = forecast["yhat"]
        pred_cols.extend(["yhat_lower", "yhat_upper"])
        rename_dict.update({"yhat_lower": "lower_bound", "yhat_upper": "upper_bound"})

    pred = forecast[pred_cols].tail(1)
    pred = pred.rename(columns=rename_dict)
    metrics = {"MAPE": np.nan, "RMSE": np.nan}
    return model, pred, metrics


def train_lstm(df: pd.DataFrame, stock_id: Optional[str] = None) -> Tuple[object, pd.DataFrame, Dict[str, float]]:
    if not cfg.enable_lstm:
        raise ImportError("LSTM å·²åœç”¨æˆ–æœªå®‰è£")
    tf = _safe_import("tensorflow")
    if tf is None:
        raise ImportError("TensorFlow æœªå®‰è£")
    import tensorflow as tf  # type: ignore

    # ä½¿ç”¨ç°¡å–®å–®è®Šé‡ LSTMï¼Œè¦–ç‚º demoï¼Œå¯æ“´å……
    series = df["y"].astype(float).values.reshape(-1, 1)
    win = 12
    X, y = [], []
    for i in range(len(series) - win):
        X.append(series[i : i + win])
        y.append(series[i + win])
    if len(X) < 10:
        raise RuntimeError("è³‡æ–™ä¸è¶³ä»¥è¨“ç·´ LSTM")
    X = np.array(X)
    y = np.array(y)

    # è®€å–å€‹è‚¡æœ€ä½³åƒæ•¸
    best = get_best_params(stock_id, "LSTM") if stock_id else None
    lstm_units = int(best.get('lstm_units', 32)) if isinstance(best, dict) else 32
    win = int(best.get('window_size', 12)) if isinstance(best, dict) else 12
    epochs = int(best.get('epochs', 50)) if isinstance(best, dict) else 50
    batch_size = int(best.get('batch_size', 16)) if isinstance(best, dict) else 16

    model = tf.keras.Sequential([
        tf.keras.layers.Input(shape=(win, 1)),
        tf.keras.layers.LSTM(lstm_units),
        tf.keras.layers.Dense(1),
    ])
    model.compile(optimizer="adam", loss="mse")
    model.fit(X, y, epochs=epochs, batch_size=batch_size, verbose=0)

    # ç”¢ç”Ÿä¸€æ­¥é æ¸¬
    last_win = series[-win:][None, :, :]
    yhat = float(model.predict(last_win, verbose=0).reshape(-1)[0])
    pred = pd.DataFrame({
        "date": [pd.to_datetime(df["date"].max()) + pd.offsets.MonthBegin(1)],
        "forecast_value": [yhat],
    })
    metrics = {"MAPE": np.nan, "RMSE": np.nan}
    return model, pred, metrics


def train_xgboost(df: pd.DataFrame, stock_id: Optional[str] = None) -> Tuple[object, pd.DataFrame, Dict[str, float]]:
    if not cfg.enable_xgboost:
        raise ImportError("XGBoost å·²åœç”¨æˆ–æœªå®‰è£")
    xgb = _safe_import("xgboost")
    if xgb is None:
        raise ImportError("XGBoost æœªå®‰è£")
    from xgboost import XGBRegressor  # type: ignore

    # å–ç‰¹å¾µèˆ‡æ¨™çš„
    target = "y"
    feature_cols = [c for c in df.columns if c not in {"date", "revenue", target, "actual_month"}]

    train_df, test_df = train_test_split_time(df)
    # ç¢ºä¿ç‰¹å¾µéƒ½æ˜¯æ•¸å€¼å‹
    X_train = train_df[feature_cols].select_dtypes(include=[np.number]).values
    y_train = train_df[target].values
    X_test = test_df[feature_cols].select_dtypes(include=[np.number]).values
    y_test = test_df[target].values

    best = get_best_params(stock_id, "XGBoost") if stock_id else None
    params = dict(
        n_estimators=300,
        max_depth=4,
        learning_rate=0.05,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=cfg.random_seed,
        objective="reg:squarederror",
    )
    if isinstance(best, dict):
        # æ›´æ–°æ‰€æœ‰èª¿æ ¡å¾Œçš„åƒæ•¸ï¼Œä¸é™åˆ¶æ–¼é è¨­åƒæ•¸
        valid_xgb_params = {
            'n_estimators', 'max_depth', 'learning_rate', 'subsample',
            'colsample_bytree', 'random_state', 'objective', 'reg_alpha',
            'reg_lambda', 'gamma', 'min_child_weight', 'max_delta_step',
            'scale_pos_weight', 'base_score', 'missing'
        }
        updated_params = {k: v for k, v in best.items() if k in valid_xgb_params}
        params.update(updated_params)
        if cfg.debug and updated_params:
            print(f"ğŸ”§ XGBoost ä½¿ç”¨èª¿æ ¡åƒæ•¸: {updated_params}")
    elif cfg.debug:
        print(f"âš ï¸  XGBoost æœªæ‰¾åˆ°èª¿æ ¡åƒæ•¸ï¼Œä½¿ç”¨é è¨­å€¼")
    model = XGBRegressor(**params)
    model.fit(X_train, y_train)
    # è‹¥è¨“ç·´é›†ç‚ºç©ºï¼ˆä¾‹å¦‚å›æ¸¬è¦–çª—å¤ªçŸ­ï¼‰ï¼Œä½¿ç”¨å…¨éƒ¨è³‡æ–™è¨“ç·´
    if X_train.size == 0 or y_train.size == 0:
        X_train = df[feature_cols].select_dtypes(include=[np.number]).values
        y_train = df[target].values
        X_test = np.empty((0, X_train.shape[1])) if X_train.size > 0 else np.empty((0, 0))
        y_test = np.array([])



    # æ¸¬è©¦é›†è©•ä¼°
    if len(X_test) > 0:
        y_pred = model.predict(X_test)
        metrics = {"MAPE": mape(y_test, y_pred), "RMSE": rmse(y_test, y_pred)}
    else:
        metrics = {"MAPE": np.nan, "RMSE": np.nan}

    # ä¸‹ä¸€æœŸç‰¹å¾µï¼ˆä½¿ç”¨æœ€å¾Œä¸€åˆ—ç‰¹å¾µå¾€å‰ç§»ï¼‰
    last_row = df.iloc[-1].copy()
    next_date = pd.to_datetime(df["date"].max()) + pd.offsets.MonthBegin(1)
    # æ»¯å¾Œç‰¹å¾µæ›´æ–°ï¼šç°¡åŒ–è™•ç†ï¼Œä½¿ç”¨ç¾æœ‰ ma èˆ‡ lag çš„å»¶ä¼¸
    next_feat = last_row.copy()
    # ä¸èƒ½ç”¨ç•¶æœŸ yï¼Œå…ˆä»¥ ma12 ä½œ proxy
    if "ma12" in df.columns:
        next_feat[target] = float(df["ma12"].iloc[-1])
    # ç§»é™¤éç‰¹å¾µæ¬„ï¼Œç¢ºä¿åªæœ‰æ•¸å€¼ç‰¹å¾µ
    numeric_features = [c for c in feature_cols if c in df.select_dtypes(include=[np.number]).columns]
    next_feat_values = next_feat[numeric_features].values.reshape(1, -1)
    yhat = float(model.predict(next_feat_values)[0])
    pred = pd.DataFrame({
        "date": [next_date],
        "forecast_value": [yhat],
    })
    return model, pred, metrics


def choose_best_model(df: pd.DataFrame, stock_id: Optional[str] = None) -> Tuple[str, pd.DataFrame, pd.DataFrame]:
    """å˜—è©¦ Prophet / LSTM / XGBoostï¼Œå›å‚³æœ€ä½³æ¨¡å‹åç¨±ã€é»ä¼°é æ¸¬ã€è©•ä¼°æŒ‡æ¨™è¡¨ã€‚æœªå®‰è£çš„è‡ªå‹•è·³éã€‚"""
    models = []
    metrics_rows = []

    # é€ä¸€å˜—è©¦ï¼Œå¿½ç•¥å®‰è£å•é¡Œ
    for name, trainer in [
        ("Prophet", train_prophet),
        ("LSTM", train_lstm),
        ("XGBoost", train_xgboost),
    ]:
        try:
            _, pred, metrics = trainer(df, stock_id=stock_id)
            models.append((name, pred, metrics))
        except Exception as e:
            metrics_rows.append({"model": name, "MAPE": np.nan, "RMSE": np.nan, "note": str(e)})

    # è‹¥æ²’æœ‰ä»»ä½•æ¨¡å‹æˆåŠŸï¼Œå›é€€åˆ°ç°¡å–®å­£ç¯€æ€§ç§»å‹•å¹³å‡
    if not models:
        preds = df[["date", "y"]].copy()
        preds["ma12"] = preds["y"].rolling(12, min_periods=1).mean()
        yhat = float(preds["ma12"].iloc[-1])
        pred = pd.DataFrame({
            "date": [pd.to_datetime(df["date"].max()) + pd.offsets.MonthBegin(1)],
            "forecast_value": [yhat],
        })
        metrics_df = pd.DataFrame(metrics_rows + [{"model": "SeasonalMA", "MAPE": np.nan, "RMSE": np.nan}])
        return "SeasonalMA", pred, metrics_df

    # é¸æ“‡ MAPE æœ€ä½è€…ï¼ˆè‹¥ç©ºå‰‡ä»¥ RMSEï¼‰
    for name, pred, metrics in models:
        metrics_rows.append({"model": name, **metrics})
    metrics_df = pd.DataFrame(metrics_rows)

    best_row = metrics_df.sort_values(by=["MAPE", "RMSE"], na_position="last").iloc[0]
    best_name = best_row["model"]

    # æ‰¾å‡ºå°æ‡‰é æ¸¬
    matching_models = [p for (n, p, _) in models if n == best_name]
    if matching_models:
        best_pred = matching_models[0]
    else:
        # å›é€€åˆ° SeasonalMA
        preds = df[["date", "y"]].copy()
        preds["ma12"] = preds["y"].rolling(12, min_periods=1).mean()
        yhat = float(preds["ma12"].iloc[-1])
        pred = pd.DataFrame({
            "date": [pd.to_datetime(df["date"].max()) + pd.offsets.MonthBegin(1)],
            "forecast_value": [yhat],
        })
        best_pred = pred
        best_name = "SeasonalMA"
    return best_name, best_pred, metrics_df


def forecast_with_model(df: pd.DataFrame, stock_id: Optional[str], model_name: str) -> Tuple[str, pd.DataFrame, pd.DataFrame]:
    """ä¾æŒ‡å®šæ¨¡å‹åç¨±é€²è¡Œé æ¸¬ï¼Œå›å‚³ (æ¨¡å‹åç¨±, é æ¸¬é»ä¼°, æŒ‡æ¨™)"""
    mapping = {
        "Prophet": train_prophet,
        "LSTM": train_lstm,
        "XGBoost": train_xgboost,
    }
    trainer = mapping.get(model_name)
    if trainer is None:
        # å›é€€è‡ªå‹•é¸æ¨¡
        return choose_best_model(df, stock_id=stock_id)
    try:
        _, pred, metrics = trainer(df, stock_id=stock_id)
        metrics_df = pd.DataFrame([{ "model": model_name, **metrics }])
        return model_name, pred, metrics_df
    except Exception:
        # è‹¥æŒ‡å®šæ¨¡å‹å¤±æ•—ï¼Œå›é€€è‡ªå‹•é¸æ¨¡
        return choose_best_model(df, stock_id=stock_id)

