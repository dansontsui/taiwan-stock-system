#!/usr/bin/env python3
"""
ç°¡åŒ–ç‰ˆé æ¸¬å™¨

ä½¿ç”¨è¨“ç·´å¥½çš„æ¨¡å‹é€²è¡Œæ½›åŠ›è‚¡é æ¸¬
"""

import sys
import os
import pandas as pd
import numpy as np
import pickle
import json
import sqlite3
from datetime import datetime
from pathlib import Path

def load_model(model_name):
    """è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹"""
    models_dir = Path("models")
    
    # è¼‰å…¥æ¨¡å‹
    model_path = models_dir / f"{model_name}_v1.0.pkl"
    if not model_path.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ: {model_path}")
    
    with open(model_path, 'rb') as f:
        model = pickle.load(f)
    
    # è¼‰å…¥scalerï¼ˆå¦‚æœæœ‰ï¼‰
    scaler = None
    scaler_path = models_dir / f"{model_name}_scaler_v1.0.pkl"
    if scaler_path.exists():
        with open(scaler_path, 'rb') as f:
            scaler = pickle.load(f)
    
    # è¼‰å…¥æ¨¡å‹è³‡è¨Š
    info_path = models_dir / f"{model_name}_info_v1.0.json"
    feature_names = None
    if info_path.exists():
        with open(info_path, 'r', encoding='utf-8') as f:
            info = json.load(f)
            feature_names = info.get('feature_names', [])
    
    return model, scaler, feature_names

def connect_database():
    """é€£æ¥è³‡æ–™åº«"""
    db_path = Path("../data/taiwan_stock.db")
    if not db_path.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°è³‡æ–™åº«æª”æ¡ˆ: {db_path}")
    
    return sqlite3.connect(str(db_path))

def get_stock_list():
    """ç²å–è‚¡ç¥¨æ¸…å–®"""
    conn = connect_database()
    
    query = """
    SELECT stock_id, stock_name, market, industry
    FROM stocks 
    WHERE is_active = 1 AND stock_id NOT LIKE '00%'
    ORDER BY stock_id
    """
    
    df = pd.read_sql_query(query, conn)
    conn.close()
    
    # éæ¿¾åªåŒ…å«æ•¸å­—çš„è‚¡ç¥¨ä»£ç¢¼
    df = df[df['stock_id'].str.isdigit()]
    
    return df

def load_latest_features():
    """è¼‰å…¥æœ€æ–°çš„ç‰¹å¾µè³‡æ–™"""
    features_dir = Path("data/features")
    
    # æ‰¾åˆ°æœ€æ–°çš„ç‰¹å¾µæª”æ¡ˆ
    feature_files = list(features_dir.glob("features_*.csv"))
    if not feature_files:
        raise FileNotFoundError("æ‰¾ä¸åˆ°ç‰¹å¾µæª”æ¡ˆ")
    
    latest_file = max(feature_files, key=lambda x: x.stat().st_mtime)
    print(f"ğŸ“Š è¼‰å…¥ç‰¹å¾µæª”æ¡ˆ: {latest_file}")
    
    features_df = pd.read_csv(latest_file)
    return features_df

def prepare_features_for_prediction(features_df, feature_names):
    """ç‚ºé æ¸¬æº–å‚™ç‰¹å¾µ"""
    # ç§»é™¤éç‰¹å¾µæ¬„ä½
    feature_columns = [col for col in features_df.columns 
                      if col not in ['stock_id', 'feature_date']]
    
    X = features_df[feature_columns].copy()
    
    # è™•ç†ç¼ºå¤±å€¼
    X = X.fillna(0)
    
    # ç¢ºä¿ç‰¹å¾µé †åºèˆ‡è¨“ç·´æ™‚ä¸€è‡´
    if feature_names:
        # æ·»åŠ ç¼ºå¤±çš„ç‰¹å¾µï¼ˆå¡«å……ç‚º0ï¼‰
        for feature in feature_names:
            if feature not in X.columns:
                X[feature] = 0
        
        # é‡æ–°æ’åºç‰¹å¾µ
        X = X[feature_names]
    
    return X

def predict_stocks(model_name="random_forest", top_k=20):
    """é æ¸¬æ½›åŠ›è‚¡"""
    print(f"ğŸ”® ä½¿ç”¨ {model_name} æ¨¡å‹é€²è¡Œé æ¸¬...")
    
    # è¼‰å…¥æ¨¡å‹
    model, scaler, feature_names = load_model(model_name)
    print(f"   âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ")
    
    # è¼‰å…¥ç‰¹å¾µè³‡æ–™
    features_df = load_latest_features()
    print(f"   âœ… ç‰¹å¾µè³‡æ–™: {len(features_df)} å€‹è‚¡ç¥¨")
    
    # æº–å‚™ç‰¹å¾µ
    X = prepare_features_for_prediction(features_df, feature_names)
    
    # æ‡‰ç”¨scalerï¼ˆå¦‚æœæœ‰ï¼‰
    if scaler:
        X = scaler.transform(X)
    
    # é€²è¡Œé æ¸¬
    predictions = model.predict(X)
    probabilities = model.predict_proba(X)[:, 1]
    
    # å‰µå»ºçµæœDataFrame
    results_df = pd.DataFrame({
        'stock_id': features_df['stock_id'],
        'feature_date': features_df['feature_date'],
        'prediction': predictions,
        'probability': probabilities
    })
    
    # ç²å–è‚¡ç¥¨åŸºæœ¬è³‡è¨Š
    stock_list = get_stock_list()

    # ç¢ºä¿stock_idé¡å‹ä¸€è‡´
    results_df['stock_id'] = results_df['stock_id'].astype(str)
    stock_list['stock_id'] = stock_list['stock_id'].astype(str)

    results_df = results_df.merge(
        stock_list[['stock_id', 'stock_name', 'market', 'industry']],
        on='stock_id',
        how='left'
    )
    
    # æŒ‰æ©Ÿç‡æ’åº
    results_df = results_df.sort_values('probability', ascending=False)
    
    # çµ±è¨ˆçµæœ
    total_stocks = len(results_df)
    predicted_positive = (results_df['prediction'] == 1).sum()
    
    print(f"   âœ… é æ¸¬å®Œæˆ")
    print(f"   ğŸ“Š ç¸½è‚¡ç¥¨æ•¸: {total_stocks}")
    print(f"   ğŸ¯ é æ¸¬ç‚ºæ½›åŠ›è‚¡: {predicted_positive} ({predicted_positive/total_stocks:.1%})")
    print(f"   ğŸ“ˆ å¹³å‡é æ¸¬æ©Ÿç‡: {results_df['probability'].mean():.3f}")
    
    return results_df.head(top_k)

def save_predictions(predictions_df, model_name):
    """å„²å­˜é æ¸¬çµæœ"""
    predictions_dir = Path("data/predictions")
    predictions_dir.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_file = predictions_dir / f"predictions_{model_name}_{timestamp}.csv"
    
    predictions_df.to_csv(output_file, index=False)
    print(f"   âœ… é æ¸¬çµæœå·²å„²å­˜: {output_file}")
    
    return output_file

def generate_ranking(model_name="random_forest", top_k=20):
    """ç”Ÿæˆæ½›åŠ›è‚¡æ’è¡Œæ¦œ"""
    print(f"ğŸ† ç”Ÿæˆæ½›åŠ›è‚¡æ’è¡Œæ¦œ (TOP {top_k})")
    print("=" * 50)
    
    # åŸ·è¡Œé æ¸¬
    ranking_df = predict_stocks(model_name, top_k)
    
    # å„²å­˜çµæœ
    rankings_dir = Path("data/rankings")
    rankings_dir.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_file = rankings_dir / f"ranking_{model_name}_{timestamp}.csv"
    ranking_df.to_csv(output_file, index=False)
    
    # é¡¯ç¤ºæ’è¡Œæ¦œ
    print(f"\nğŸ¯ æ½›åŠ›è‚¡æ’è¡Œæ¦œ (TOP {len(ranking_df)}):")
    print("=" * 80)
    print(f"{'æ’å':>4} {'è‚¡ç¥¨ä»£ç¢¼':>8} {'è‚¡ç¥¨åç¨±':<12} {'é æ¸¬æ©Ÿç‡':>8} {'é æ¸¬çµæœ':>8} {'å¸‚å ´':>6}")
    print("-" * 80)
    
    for i, (_, row) in enumerate(ranking_df.iterrows()):
        rank = i + 1
        stock_id = row['stock_id']
        stock_name = row['stock_name'][:10] if pd.notna(row['stock_name']) else 'N/A'
        probability = row['probability']
        prediction = "çœ‹æ¼²" if row['prediction'] == 1 else "çœ‹è·Œ"
        market = row['market'] if pd.notna(row['market']) else 'N/A'
        
        print(f"{rank:>4} {stock_id:>8} {stock_name:<12} {probability:>8.3f} {prediction:>8} {market:>6}")
    
    print("=" * 80)
    print(f"ğŸ“ å®Œæ•´çµæœå·²å„²å­˜: {output_file}")
    
    return ranking_df, output_file

def predict_specific_stocks(stock_ids, model_name="random_forest"):
    """é æ¸¬ç‰¹å®šè‚¡ç¥¨"""
    print(f"ğŸ¯ é æ¸¬ç‰¹å®šè‚¡ç¥¨: {', '.join(stock_ids)}")
    print("=" * 50)
    
    # è¼‰å…¥æ¨¡å‹
    model, scaler, feature_names = load_model(model_name)
    
    # è¼‰å…¥ç‰¹å¾µè³‡æ–™
    features_df = load_latest_features()
    
    # éæ¿¾æŒ‡å®šè‚¡ç¥¨
    target_features = features_df[features_df['stock_id'].isin(stock_ids)]
    
    if target_features.empty:
        print("âŒ æ‰¾ä¸åˆ°æŒ‡å®šè‚¡ç¥¨çš„ç‰¹å¾µè³‡æ–™")
        return None
    
    # æº–å‚™ç‰¹å¾µ
    X = prepare_features_for_prediction(target_features, feature_names)
    
    # æ‡‰ç”¨scalerï¼ˆå¦‚æœæœ‰ï¼‰
    if scaler:
        X = scaler.transform(X)
    
    # é€²è¡Œé æ¸¬
    predictions = model.predict(X)
    probabilities = model.predict_proba(X)[:, 1]
    
    # å‰µå»ºçµæœ
    results = []
    for i, (_, row) in enumerate(target_features.iterrows()):
        results.append({
            'stock_id': row['stock_id'],
            'prediction': "çœ‹æ¼²" if predictions[i] == 1 else "çœ‹è·Œ",
            'probability': probabilities[i],
            'confidence': "é«˜" if probabilities[i] > 0.7 or probabilities[i] < 0.3 else "ä¸­"
        })
    
    # é¡¯ç¤ºçµæœ
    print(f"ğŸ“Š é æ¸¬çµæœ:")
    print("-" * 50)
    for result in results:
        print(f"   {result['stock_id']}: {result['prediction']} (æ©Ÿç‡: {result['probability']:.3f}, ä¿¡å¿ƒ: {result['confidence']})")
    
    return results

def main():
    """ä¸»ç¨‹å¼"""
    print("ğŸ”® ç°¡åŒ–ç‰ˆé æ¸¬å™¨")
    print("=" * 50)
    
    # æª¢æŸ¥å¯ç”¨æ¨¡å‹
    models_dir = Path("models")
    available_models = []
    for model_file in models_dir.glob("*_v1.0.pkl"):
        model_name = model_file.stem.replace("_v1.0", "")
        if not model_name.endswith("_scaler"):
            available_models.append(model_name)
    
    if not available_models:
        print("âŒ æ‰¾ä¸åˆ°è¨“ç·´å¥½çš„æ¨¡å‹")
        print("è«‹å…ˆåŸ·è¡Œæ¨¡å‹è¨“ç·´: python simple_train.py")
        return
    
    print(f"ğŸ“‹ å¯ç”¨æ¨¡å‹: {', '.join(available_models)}")
    
    # ç²å–åƒæ•¸
    if len(sys.argv) >= 2:
        action = sys.argv[1]
        model_name = sys.argv[2] if len(sys.argv) >= 3 else "random_forest"
        top_k = int(sys.argv[3]) if len(sys.argv) >= 4 else 20
    else:
        print("\nè«‹é¸æ“‡åŠŸèƒ½:")
        print("1. ç”Ÿæˆæ½›åŠ›è‚¡æ’è¡Œæ¦œ")
        print("2. é æ¸¬ç‰¹å®šè‚¡ç¥¨")
        choice = input("è«‹è¼¸å…¥é¸æ“‡ (1-2): ").strip()
        action = "ranking" if choice == "1" else "specific"

        # é¸æ“‡æ¨¡å‹
        model_name = input(f"è«‹é¸æ“‡æ¨¡å‹ ({'/'.join(available_models)}, é è¨­: random_forest): ").strip()
        if not model_name:
            model_name = "random_forest"

        top_k = 20
    
    try:
        if action == "ranking":
            if len(sys.argv) < 4:  # å¦‚æœæ²’æœ‰é€šéå‘½ä»¤åˆ—åƒæ•¸æŒ‡å®š
                top_k_input = input("è«‹è¼¸å…¥æ’è¡Œæ¦œæ•¸é‡ (é è¨­: 20): ").strip()
                top_k = int(top_k_input) if top_k_input else 20

            ranking_df, output_file = generate_ranking(model_name, top_k)
            
        elif action == "specific":
            stock_ids_input = input("è«‹è¼¸å…¥è‚¡ç¥¨ä»£ç¢¼ (é€—è™Ÿåˆ†éš”): ").strip()
            stock_ids = [s.strip() for s in stock_ids_input.split(',')]
            
            results = predict_specific_stocks(stock_ids, model_name)
            
        else:
            print("âŒ ç„¡æ•ˆçš„åŠŸèƒ½é¸æ“‡")
    
    except Exception as e:
        print(f"âŒ é æ¸¬å¤±æ•—: {e}")

if __name__ == "__main__":
    main()
