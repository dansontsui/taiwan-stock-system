#!/usr/bin/env python3
"""
æ½›åŠ›è‚¡é æ¸¬ç³»çµ±ä¸»ç¨‹å¼

æä¾›å‘½ä»¤åˆ—ä»‹é¢ä¾†åŸ·è¡Œå„ç¨®åŠŸèƒ½ï¼š
- ç‰¹å¾µç”Ÿæˆ
- æ¨¡å‹è¨“ç·´
- é æ¸¬åŸ·è¡Œ
- çµæœåˆ†æ

ä½¿ç”¨æ–¹æ³•:
    python main.py --help
    python main.py generate-features --stock-ids 2330,2317 --date 2024-06-30
    python main.py train-models --features-file features.csv --targets-file targets.csv
    python main.py predict --stock-ids 2330,2317 --model lightgbm
    python main.py ranking --top-k 50
"""

import argparse
import logging
import sys
from pathlib import Path
from datetime import datetime, timedelta
import pandas as pd

# æ·»åŠ å°ˆæ¡ˆè·¯å¾‘
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

try:
    from src.features.feature_engineering import FeatureEngineer
    from src.features.target_generator import TargetGenerator
    from src.models.model_trainer import ModelTrainer
    from src.models.predictor import Predictor
    from src.utils.database import DatabaseManager
    from src.utils.logger import setup_logger
    from config.config import ensure_directories, get_date_ranges
except ImportError as e:
    print(f"âŒ å°å…¥æ¨¡çµ„å¤±æ•—: {e}")
    print("è«‹ç¢ºä¿åœ¨ potential_stock_predictor ç›®éŒ„ä¸‹åŸ·è¡Œæ­¤ç¨‹å¼")
    sys.exit(1)

# è¨­ç½®æ—¥èªŒ
logger = setup_logger('potential_stock_predictor')

def setup_argparse():
    """è¨­ç½®å‘½ä»¤åˆ—åƒæ•¸è§£æ"""
    parser = argparse.ArgumentParser(
        description='æ½›åŠ›è‚¡é æ¸¬ç³»çµ±',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹:
  # ç”Ÿæˆç‰¹å¾µ
  python main.py generate-features --date 2024-06-30
  
  # è¨“ç·´æ¨¡å‹
  python main.py train-models
  
  # åŸ·è¡Œé æ¸¬
  python main.py predict --model lightgbm
  
  # ç”Ÿæˆæ’è¡Œæ¦œ
  python main.py ranking --top-k 50
        """
    )
    
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # ç”Ÿæˆç‰¹å¾µå‘½ä»¤
    features_parser = subparsers.add_parser('generate-features', help='ç”Ÿæˆç‰¹å¾µ')
    features_parser.add_argument('--stock-ids', type=str, help='è‚¡ç¥¨ä»£ç¢¼åˆ—è¡¨ï¼ˆé€—è™Ÿåˆ†éš”ï¼‰')
    features_parser.add_argument('--date', type=str, help='ç‰¹å¾µè¨ˆç®—æ—¥æœŸ (YYYY-MM-DD)')
    features_parser.add_argument('--output', type=str, help='è¼¸å‡ºæª”æ¡ˆè·¯å¾‘')
    
    # ç”Ÿæˆç›®æ¨™è®Šæ•¸å‘½ä»¤
    targets_parser = subparsers.add_parser('generate-targets', help='ç”Ÿæˆç›®æ¨™è®Šæ•¸')
    targets_parser.add_argument('--stock-ids', type=str, help='è‚¡ç¥¨ä»£ç¢¼åˆ—è¡¨ï¼ˆé€—è™Ÿåˆ†éš”ï¼‰')
    targets_parser.add_argument('--start-date', type=str, help='é–‹å§‹æ—¥æœŸ (YYYY-MM-DD)')
    targets_parser.add_argument('--end-date', type=str, help='çµæŸæ—¥æœŸ (YYYY-MM-DD)')
    targets_parser.add_argument('--frequency', type=str, choices=['monthly', 'quarterly'], 
                               default='quarterly', help='é »ç‡')
    targets_parser.add_argument('--output', type=str, help='è¼¸å‡ºæª”æ¡ˆè·¯å¾‘')
    
    # è¨“ç·´æ¨¡å‹å‘½ä»¤
    train_parser = subparsers.add_parser('train-models', help='è¨“ç·´æ¨¡å‹')
    train_parser.add_argument('--features-file', type=str, help='ç‰¹å¾µæª”æ¡ˆè·¯å¾‘')
    train_parser.add_argument('--targets-file', type=str, help='ç›®æ¨™è®Šæ•¸æª”æ¡ˆè·¯å¾‘')
    train_parser.add_argument('--models', type=str, help='æ¨¡å‹é¡å‹åˆ—è¡¨ï¼ˆé€—è™Ÿåˆ†éš”ï¼‰')
    
    # é æ¸¬å‘½ä»¤
    predict_parser = subparsers.add_parser('predict', help='åŸ·è¡Œé æ¸¬')
    predict_parser.add_argument('--stock-ids', type=str, help='è‚¡ç¥¨ä»£ç¢¼åˆ—è¡¨ï¼ˆé€—è™Ÿåˆ†éš”ï¼‰')
    predict_parser.add_argument('--date', type=str, help='é æ¸¬æ—¥æœŸ (YYYY-MM-DD)')
    predict_parser.add_argument('--model', type=str, default='lightgbm', help='æ¨¡å‹é¡å‹')
    predict_parser.add_argument('--output', type=str, help='è¼¸å‡ºæª”æ¡ˆè·¯å¾‘')
    
    # æ’è¡Œæ¦œå‘½ä»¤
    ranking_parser = subparsers.add_parser('ranking', help='ç”Ÿæˆæ½›åŠ›è‚¡æ’è¡Œæ¦œ')
    ranking_parser.add_argument('--date', type=str, help='é æ¸¬æ—¥æœŸ (YYYY-MM-DD)')
    ranking_parser.add_argument('--model', type=str, default='lightgbm', help='æ¨¡å‹é¡å‹')
    ranking_parser.add_argument('--top-k', type=int, default=50, help='è¿”å›å‰Kå€‹è‚¡ç¥¨')
    ranking_parser.add_argument('--output', type=str, help='è¼¸å‡ºæª”æ¡ˆè·¯å¾‘')
    
    # æ¸¬è©¦å‘½ä»¤
    test_parser = subparsers.add_parser('test', help='åŸ·è¡Œç³»çµ±æ¸¬è©¦')
    test_parser.add_argument('--module', type=str, help='æ¸¬è©¦æ¨¡çµ„åç¨±')
    
    return parser

def generate_features_command(args):
    """åŸ·è¡Œç‰¹å¾µç”Ÿæˆå‘½ä»¤"""
    logger.info("é–‹å§‹ç”Ÿæˆç‰¹å¾µ...")
    
    # åˆå§‹åŒ–
    db_manager = DatabaseManager()
    feature_engineer = FeatureEngineer(db_manager)
    
    # è™•ç†åƒæ•¸
    if args.stock_ids:
        stock_ids = args.stock_ids.split(',')
    else:
        stock_list = db_manager.get_stock_list(exclude_patterns=['00'])
        stock_ids = stock_list['stock_id'].tolist()
    
    date = args.date or datetime.now().strftime('%Y-%m-%d')
    
    # ç”Ÿæˆç‰¹å¾µ
    features_df = feature_engineer.generate_batch_features(stock_ids, date)
    
    if features_df.empty:
        logger.error("æ²’æœ‰ç”Ÿæˆä»»ä½•ç‰¹å¾µ")
        return
    
    # å„²å­˜çµæœ
    output_path = args.output or f"data/features/features_{date}.csv"
    Path(output_path).parent.mkdir(parents=True, exist_ok=True)
    features_df.to_csv(output_path, index=False)
    
    logger.info(f"ç‰¹å¾µç”Ÿæˆå®Œæˆï¼Œå„²å­˜åˆ°: {output_path}")
    logger.info(f"ç”Ÿæˆ {len(features_df)} å€‹æ¨£æœ¬ï¼Œ{len(features_df.columns)-2} å€‹ç‰¹å¾µ")

def generate_targets_command(args):
    """åŸ·è¡Œç›®æ¨™è®Šæ•¸ç”Ÿæˆå‘½ä»¤"""
    logger.info("é–‹å§‹ç”Ÿæˆç›®æ¨™è®Šæ•¸...")
    
    # åˆå§‹åŒ–
    db_manager = DatabaseManager()
    target_generator = TargetGenerator(db_manager)
    
    # è™•ç†åƒæ•¸
    if args.stock_ids:
        stock_ids = args.stock_ids.split(',')
    else:
        stock_list = db_manager.get_stock_list(exclude_patterns=['00'])
        stock_ids = stock_list['stock_id'].tolist()
    
    start_date = args.start_date or '2022-01-01'
    end_date = args.end_date or datetime.now().strftime('%Y-%m-%d')
    frequency = args.frequency
    
    # ç”Ÿæˆç›®æ¨™è®Šæ•¸
    targets_df = target_generator.create_time_series_targets(
        stock_ids, start_date, end_date, frequency
    )
    
    if targets_df.empty:
        logger.error("æ²’æœ‰ç”Ÿæˆä»»ä½•ç›®æ¨™è®Šæ•¸")
        return
    
    # å„²å­˜çµæœ
    output_path = args.output or f"data/targets/targets_{frequency}_{end_date}.csv"
    Path(output_path).parent.mkdir(parents=True, exist_ok=True)
    targets_df.to_csv(output_path, index=False)
    
    # åˆ†æç›®æ¨™è®Šæ•¸åˆ†å¸ƒ
    analysis = target_generator.analyze_target_distribution(targets_df)
    logger.info(f"ç›®æ¨™è®Šæ•¸ç”Ÿæˆå®Œæˆï¼Œå„²å­˜åˆ°: {output_path}")
    logger.info(f"ç”Ÿæˆ {len(targets_df)} å€‹æ¨£æœ¬ï¼Œæ­£æ¨£æœ¬æ¯”ä¾‹: {analysis.get('positive_ratio', 0):.2%}")

def train_models_command(args):
    """åŸ·è¡Œæ¨¡å‹è¨“ç·´å‘½ä»¤"""
    logger.info("é–‹å§‹è¨“ç·´æ¨¡å‹...")
    
    # è¼‰å…¥è³‡æ–™
    if args.features_file and args.targets_file:
        features_df = pd.read_csv(args.features_file)
        targets_df = pd.read_csv(args.targets_file)
    else:
        logger.error("è«‹æä¾›ç‰¹å¾µæª”æ¡ˆå’Œç›®æ¨™è®Šæ•¸æª”æ¡ˆè·¯å¾‘")
        return
    
    # åˆå§‹åŒ–è¨“ç·´å™¨
    trainer = ModelTrainer()
    
    # è¨“ç·´æ¨¡å‹
    results = trainer.train_all_models(features_df, targets_df)
    
    if results:
        logger.info("æ¨¡å‹è¨“ç·´å®Œæˆ")
        for model_type, result in results.items():
            metrics = result['metrics']
            logger.info(f"{model_type}: AUC={metrics['roc_auc']:.4f}, F1={metrics['f1_score']:.4f}")
    else:
        logger.error("æ¨¡å‹è¨“ç·´å¤±æ•—")

def predict_command(args):
    """åŸ·è¡Œé æ¸¬å‘½ä»¤"""
    logger.info("é–‹å§‹åŸ·è¡Œé æ¸¬...")
    
    # åˆå§‹åŒ–é æ¸¬å™¨
    predictor = Predictor()
    
    # è™•ç†åƒæ•¸
    stock_ids = args.stock_ids.split(',') if args.stock_ids else None
    date = args.date or datetime.now().strftime('%Y-%m-%d')
    model_type = args.model
    
    # åŸ·è¡Œé æ¸¬
    predictions_df = predictor.predict_batch(stock_ids, date, model_type)
    
    if predictions_df.empty:
        logger.error("æ²’æœ‰é æ¸¬çµæœ")
        return
    
    # å„²å­˜çµæœ
    output_path = args.output or f"data/predictions/predictions_{model_type}_{date}.csv"
    Path(output_path).parent.mkdir(parents=True, exist_ok=True)
    predictions_df.to_csv(output_path, index=False)
    
    # çµ±è¨ˆçµæœ
    success_count = (predictions_df['status'] == 'success').sum()
    positive_count = (predictions_df['prediction'] == 1).sum()
    
    logger.info(f"é æ¸¬å®Œæˆï¼Œå„²å­˜åˆ°: {output_path}")
    logger.info(f"æˆåŠŸé æ¸¬ {success_count} å€‹è‚¡ç¥¨ï¼Œæ½›åŠ›è‚¡ {positive_count} å€‹")

def ranking_command(args):
    """åŸ·è¡Œæ’è¡Œæ¦œç”Ÿæˆå‘½ä»¤"""
    logger.info("é–‹å§‹ç”Ÿæˆæ½›åŠ›è‚¡æ’è¡Œæ¦œ...")
    
    # åˆå§‹åŒ–é æ¸¬å™¨
    predictor = Predictor()
    
    # è™•ç†åƒæ•¸
    date = args.date or datetime.now().strftime('%Y-%m-%d')
    model_type = args.model
    top_k = args.top_k
    
    # ç”Ÿæˆæ’è¡Œæ¦œ
    ranking_df = predictor.generate_potential_stock_ranking(date, model_type, top_k)
    
    if ranking_df.empty:
        logger.error("æ²’æœ‰ç”Ÿæˆæ’è¡Œæ¦œ")
        return
    
    # å„²å­˜çµæœ
    output_path = args.output or f"data/rankings/ranking_{model_type}_{date}.csv"
    Path(output_path).parent.mkdir(parents=True, exist_ok=True)
    ranking_df.to_csv(output_path, index=False)
    
    logger.info(f"æ½›åŠ›è‚¡æ’è¡Œæ¦œç”Ÿæˆå®Œæˆï¼Œå„²å­˜åˆ°: {output_path}")
    logger.info(f"æ’è¡Œæ¦œåŒ…å« {len(ranking_df)} å€‹è‚¡ç¥¨")
    
    # é¡¯ç¤ºå‰10å
    print("\nğŸ† æ½›åŠ›è‚¡æ’è¡Œæ¦œ (å‰10å):")
    print("=" * 80)
    for _, row in ranking_df.head(10).iterrows():
        print(f"{row['rank']:2d}. {row['stock_id']} {row.get('stock_name', '')} - "
              f"æ©Ÿç‡: {row['probability']:.3f}")

def test_command(args):
    """åŸ·è¡Œæ¸¬è©¦å‘½ä»¤"""
    logger.info("é–‹å§‹åŸ·è¡Œç³»çµ±æ¸¬è©¦...")
    
    import unittest
    
    if args.module:
        # åŸ·è¡Œç‰¹å®šæ¨¡çµ„æ¸¬è©¦
        module_name = f"tests.{args.module}"
        suite = unittest.TestLoader().loadTestsFromName(module_name)
    else:
        # åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦
        suite = unittest.TestLoader().discover('tests', pattern='test_*.py')
    
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    if result.wasSuccessful():
        logger.info("æ‰€æœ‰æ¸¬è©¦é€šé")
    else:
        logger.error(f"æ¸¬è©¦å¤±æ•—: {len(result.failures)} å€‹å¤±æ•—, {len(result.errors)} å€‹éŒ¯èª¤")

def main():
    """ä¸»ç¨‹å¼"""
    # ç¢ºä¿ç›®éŒ„å­˜åœ¨
    ensure_directories()
    
    # è§£æå‘½ä»¤åˆ—åƒæ•¸
    parser = setup_argparse()
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    try:
        # åŸ·è¡Œå°æ‡‰å‘½ä»¤
        if args.command == 'generate-features':
            generate_features_command(args)
        elif args.command == 'generate-targets':
            generate_targets_command(args)
        elif args.command == 'train-models':
            train_models_command(args)
        elif args.command == 'predict':
            predict_command(args)
        elif args.command == 'ranking':
            ranking_command(args)
        elif args.command == 'test':
            test_command(args)
        else:
            logger.error(f"æœªçŸ¥å‘½ä»¤: {args.command}")
            parser.print_help()
    
    except Exception as e:
        logger.error(f"åŸ·è¡Œå‘½ä»¤å¤±æ•—: {e}")
        raise

if __name__ == "__main__":
    main()
