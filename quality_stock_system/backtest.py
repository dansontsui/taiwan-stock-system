# -*- coding: utf-8 -*-
from __future__ import annotations
import os
import json
import pandas as pd
import numpy as np
from typing import Dict, List
from .utils import get_conn, OUTPUT_DIR, safe_write_csv, safe_write_json, log
import datetime


def load_quality_list(profile: str = 'conservative') -> pd.DataFrame:
    json_path = os.path.join(OUTPUT_DIR, f'quality_list_{profile}.json')
    if not os.path.exists(json_path):
        raise FileNotFoundError(f'æ‰¾ä¸åˆ°æ¸…å–® JSON: {json_path}ï¼Œè«‹å…ˆåŸ·è¡ŒåŒ¯å‡ºæ¸…å–®')
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    df = pd.DataFrame(data)
    if df.empty or 'stock_id' not in df.columns:
        raise ValueError('æ¸…å–®ç‚ºç©ºï¼Œç„¡æˆåˆ†è‚¡å¯å›æ¸¬')
    # åŠ å…¥æ’åï¼ˆ1 é–‹å§‹ï¼‰
    df = df.reset_index().rename(columns={'index': 'rank'})
    df['rank'] = df['rank'] + 1
    return df[['stock_id','rank']]


def _first_last_prices(df: pd.DataFrame) -> pd.DataFrame:
    # df: columns [stock_id, date, close_price]
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'])
    df['year'] = df['date'].dt.year
    first = df.sort_values('date').groupby(['stock_id','year']).first().reset_index().rename(columns={'close_price':'close_price_first'})
    last = df.sort_values('date').groupby(['stock_id','year']).last().reset_index().rename(columns={'close_price':'close_price_last'})
    rep = last.merge(first, on=['stock_id','year'])
    # å®‰å…¨è¨ˆç®—å¹´åº¦å ±é…¬ï¼Œé¿å…é™¤ä»¥ 0 æˆ– inf
    rep['year_return_raw'] = np.where((rep['close_price_first'] > 0) & (rep['close_price_last'] > 0),
                                      rep['close_price_last'] / rep['close_price_first'] - 1.0,
                                      np.nan)
    # ä¿ç•™åŸåƒ¹ä»¥ä¾›æ˜ç´°è¼¸å‡º
    return rep[['stock_id','year','close_price_first','close_price_last','year_return_raw']]


def _load_dividends(conn, stock_ids: List[str], year: int) -> pd.DataFrame:
    """è¼‰å…¥æŒ‡å®šå¹´åº¦çš„è‚¡åˆ©è³‡æ–™ï¼ˆç¾é‡‘è‚¡åˆ©ã€è‚¡ç¥¨è‚¡åˆ©ï¼‰ã€‚
    å›å‚³ï¼š
      - è‹¥æœ‰æ—¥æœŸæ¬„ä½ï¼šcolumns = [stock_id, dt, cash_amt, stock_ratio]
      - è‹¥ç„¡æ—¥æœŸæ¬„ä½ï¼šcolumns = [stock_id, cash_div_ps, stock_ratio_total]ï¼ˆå…¨å¹´ç¸½å’Œï¼‰
    """
    try:
        cols = pd.read_sql_query("PRAGMA table_info(dividend_policies)", conn)
        available = set(cols['name'].tolist()) if not cols.empty else set()
        if not available:
            return pd.DataFrame({'stock_id': stock_ids, 'cash_div_ps': [0.0]*len(stock_ids)})
        date_col = None
        for c in ['ex_date', 'pay_date', 'announcement_date', 'record_date', 'date']:
            if c in available:
                date_col = c
                break
        # æ¬„ä½å‘½åå°é½Šï¼š
        #  - stock_earnings_distrubtionï¼šè‚¡ç¥¨è‚¡åˆ©ï¼ˆæ¯”ç‡ï¼Œä¾‹å¦‚ 0.1 è¡¨ç¤ºé… 10% è‚¡ç¥¨è‚¡åˆ©ï¼‰
        #  - cash_earnings_distrubtionï¼šç¾é‡‘è‚¡åˆ©ï¼ˆæ¯è‚¡ï¼‰
        cash_cols = [c for c in ['cash_earnings_distribution','cash_earnings_distrubtion','cash_statutory_surplus','cash_capital_reserve','cash_dividend'] if c in available]
        if 'stock_earnings_distribution' in available:
            stock_col = 'stock_earnings_distribution'
        elif 'stock_earnings_distrubtion' in available:
            stock_col = 'stock_earnings_distrubtion'
        else:
            stock_col = None
        if not cash_cols and stock_col is None:
            return pd.DataFrame({'stock_id': stock_ids, 'cash_div_ps': [0.0]*len(stock_ids), 'stock_ratio_total':[0.0]*len(stock_ids)})
        q_marks = ','.join(['?']*len(stock_ids))
        if date_col:
            select_cols = [f"{'+'.join(cash_cols)} AS cash_amt"]
            if stock_col:
                select_cols.append(f"{stock_col} AS stock_ratio")
            else:
                select_cols.append("0.0 AS stock_ratio")
            sel = ', '.join(select_cols)
            df = pd.read_sql_query(
                f"SELECT stock_id, {date_col} AS dt, {sel} FROM dividend_policies WHERE stock_id IN ({q_marks})",
                conn, params=stock_ids
            )
            if df.empty:
                return pd.DataFrame({'stock_id': stock_ids, 'cash_div_ps': [0.0]*len(stock_ids), 'stock_ratio_total':[0.0]*len(stock_ids)})
            df['dt'] = pd.to_datetime(df['dt'], errors='coerce')
            df['year'] = df['dt'].dt.year
            df = df[df['year'] == int(year)][['stock_id','dt','cash_amt','stock_ratio']]
            return df
        else:
            year_col = 'year' if 'year' in available else None
            if year_col is None:
                return pd.DataFrame({'stock_id': stock_ids, 'cash_div_ps': [0.0]*len(stock_ids)})
            select_cols = [f"{'+'.join(cash_cols)} AS cash_amt"]
            if stock_col:
                select_cols.append(f"{stock_col} AS stock_ratio")
            else:
                select_cols.append("0.0 AS stock_ratio")
            sel = ', '.join(select_cols)
            df = pd.read_sql_query(
                f"SELECT stock_id, {year_col} AS y, {sel} FROM dividend_policies WHERE stock_id IN ({q_marks}) AND {year_col}=?",
                conn, params=(stock_ids + [str(year)])
            )
            if df.empty:
                return pd.DataFrame({'stock_id': stock_ids, 'cash_div_ps': [0.0]*len(stock_ids), 'stock_ratio_total':[0.0]*len(stock_ids)})
            def _to_year(v):
                try:
                    if isinstance(v, str) and v.endswith('å¹´'):
                        return int(v[:-1]) + 1911
                    return int(v)
                except Exception:
                    return None
            df['y'] = df['y'].apply(_to_year)
            df = df[df['y'] == int(year)]
            df_cash = df.groupby('stock_id', as_index=False)['cash_amt'].sum().rename(columns={'cash_amt':'cash_div_ps'})
            df_stock = df.groupby('stock_id', as_index=False)['stock_ratio'].sum().rename(columns={'stock_ratio':'stock_ratio_total'})
            out = df_cash.merge(df_stock, on='stock_id', how='outer').fillna(0.0)
            return out
    except Exception:
        return pd.DataFrame({'stock_id': stock_ids, 'cash_div_ps': [0.0]*len(stock_ids)})


def _apply_stoploss_and_dividends(prices: pd.DataFrame,
                                   trading_year: int,
                                   include_dividends: bool,
                                   sl_pct: float | None,
                                   conn,
                                   tp_pct: float | None = None,
                                   tsl_pct: float | None = None,
                                   trigger_priority: str = 'chronological') -> pd.DataFrame:
    """å°å–®ä¸€å¹´åº¦é€æª”è¨ˆç®—ï¼šé€²å ´/å‡ºå ´/åœæ/åœåˆ©/ç§»å‹•åœæã€å«æ¯/ä¸å«æ¯å ±é…¬ã€‚
    prices: columns [stock_id, date, close_price]ï¼ˆå·²ç‚ºè©²å¹´åº¦è³‡æ–™ï¼‰
    å›å‚³ï¼šstock_id, year, entry_date, exit_date, entry_price, exit_price, raw_return, cash_div, total_return
    """
    if prices.empty:
        return pd.DataFrame(columns=['stock_id','year','entry_date','exit_date','entry_price','exit_price','raw_return','cash_div','total_return'])
    prices = prices.copy()
    prices['date'] = pd.to_datetime(prices['date'], errors='coerce')
    out_rows = []
    stock_ids = sorted(prices['stock_id'].astype(str).unique().tolist())
    # é å…ˆè¼‰å…¥å…¨å¹´ç¾é‡‘è‚¡åˆ©ï¼ˆè‹¥æœ‰æ—¥æœŸæ¬„ä½ï¼Œä¿ç•™é€ç­†ï¼Œå¦å‰‡åªå¾—å…¨å¹´ç¸½é¡ï¼‰
    div_df = pd.DataFrame({'stock_id': stock_ids, 'cash_div_ps': [0.0]*len(stock_ids)})
    if include_dividends:
        got_dates = False
        try:
            div_df = _load_dividends(conn, stock_ids, trading_year)
            got_dates = ('dt' in div_df.columns)
        except Exception:
            pass
        if div_df is None or div_df.empty:
            div_df = pd.DataFrame({'stock_id': stock_ids, 'cash_div_ps': [0.0]*len(stock_ids)})
        if 'stock_id' in div_df.columns:
            div_df['stock_id'] = div_df['stock_id'].astype(str)
    for sid, g in prices.groupby('stock_id'):
        g = g.sort_values('date').reset_index(drop=True)
        entry_date = g['date'].iloc[0]
        entry_p = float(g['close_price'].iloc[0])
        exit_date = g['date'].iloc[-1]
        exit_p = float(g['close_price'].iloc[-1])
        exit_reason = 'æœŸæœ«'

        # è‹¥æœ‰æ—¥æœŸå‹è‚¡åˆ©è³‡æ–™ï¼šä»¥ã€Œè³‡ç”¢åƒ¹å€¼ã€ï¼ˆprice*shares+cashï¼‰åšåœæ/åœåˆ©/ç§»å‹•åœæåˆ¤æ–·
        has_dt = include_dividends and ('dt' in div_df.columns)
        if has_dt and entry_p > 0:
            # æ¨™æº–åŒ–ï¼šæœŸåˆè³‡ç”¢å€¼=1.0ï¼Œshares=1/entry_p
            shares = 1.0 / entry_p
            cash_recv = 0.0
            value_entry = 1.0
            sl_val_thr = (1.0 - float(sl_pct)) if sl_pct is not None else None
            tp_val_thr = (1.0 + float(tp_pct)) if tp_pct is not None else None
            rolling_high_val = value_entry
            # æº–å‚™è©²è‚¡çš„è‚¡åˆ©äº‹ä»¶ï¼ˆæ—¥æœŸæ’åºï¼‰
            ev = div_df[div_df['stock_id']==str(sid)].copy()
            ev['dt'] = pd.to_datetime(ev['dt'], errors='coerce')
            ev = ev.dropna(subset=['dt']).sort_values('dt') if not ev.empty else ev
            ev_idx = 0
            ev_list = ev[['dt','cash_amt','stock_ratio']].values.tolist() if not ev.empty else []
            # é€æ—¥ï¼šå…ˆæ‡‰ç”¨ <= ç•¶æ—¥çš„è‚¡åˆ©äº‹ä»¶ï¼Œå†è¨ˆç®—ç•¶æ—¥è³‡ç”¢å€¼
            for i in range(1, len(g)):
                d = g['date'].iloc[i]
                px = float(g['close_price'].iloc[i])
                # å¥—ç”¨æ‰€æœ‰ dt<=d çš„äº‹ä»¶
                while ev_idx < len(ev_list) and pd.to_datetime(ev_list[ev_idx][0]) <= d:
                    _, cash_amt_i, stock_ratio_i = ev_list[ev_idx]
                    stock_ratio_i = float(stock_ratio_i) if pd.notna(stock_ratio_i) else 0.0
                    cash_amt_i = float(cash_amt_i) if pd.notna(cash_amt_i) else 0.0
                    if stock_ratio_i != 0.0:
                        shares *= (1.0 + stock_ratio_i)
                    if cash_amt_i != 0.0:
                        cash_recv += cash_amt_i * shares
                    ev_idx += 1
                # è¨ˆç®—ç•¶æ—¥è³‡ç”¢å€¼
                val_now = px * shares + cash_recv
                rolling_high_val = max(rolling_high_val, val_now)
                hits = []
                if sl_val_thr is not None and val_now <= sl_val_thr:
                    hits.append(('åœæ', d, px))
                if tp_val_thr is not None and val_now >= tp_val_thr:
                    hits.append(('åœåˆ©', d, px))
                if tsl_pct is not None and rolling_high_val>0 and val_now <= rolling_high_val * (1.0 - float(tsl_pct)):
                    hits.append(('ç§»å‹•åœæ', d, px))
                if not hits:
                    continue
                if trigger_priority == 'tp_first':
                    order = {'åœåˆ©':0,'åœæ':1,'ç§»å‹•åœæ':2}
                elif trigger_priority == 'sl_first':
                    order = {'åœæ':0,'åœåˆ©':1,'ç§»å‹•åœæ':2}
                else:
                    order = {'åœæ':0,'åœåˆ©':1,'ç§»å‹•åœæ':2}
                hits.sort(key=lambda x: order.get(x[0], 99))
                exit_reason, exit_date, exit_p = hits[0]
                break
            # å‡ºå ´æ™‚çš„è³‡ç”¢å€¼ï¼ˆè‹¥æœªæå‰å‡ºå ´ï¼Œéœ€æŠŠæœŸæœ«ä¹‹å‰æ‰€æœ‰äº‹ä»¶å¥—ç”¨ï¼‰
            if exit_reason == 'æœŸæœ«':
                # å¥—ç”¨æ‰€æœ‰å‰©é¤˜äº‹ä»¶åˆ°æœŸæœ«
                while ev_idx < len(ev_list) and pd.to_datetime(ev_list[ev_idx][0]) <= exit_date:
                    _, cash_amt_i, stock_ratio_i = ev_list[ev_idx]
                    stock_ratio_i = float(stock_ratio_i) if pd.notna(stock_ratio_i) else 0.0
                    cash_amt_i = float(cash_amt_i) if pd.notna(cash_amt_i) else 0.0
                    if stock_ratio_i != 0.0:
                        shares *= (1.0 + stock_ratio_i)
                    if cash_amt_i != 0.0:
                        cash_recv += cash_amt_i * shares
                    ev_idx += 1
            # æœ€çµ‚è³‡ç”¢å€¼
            val_exit = exit_p * shares + cash_recv
            raw_ret = (exit_p/entry_p - 1.0) if (entry_p>0 and exit_p>0) else np.nan
            cash_div = cash_recv
            stock_ratio_agg = None  # å·²ä»¥ shares æ¨¡æ“¬ï¼Œä¸å†ç”¨å€å¢è¿‘ä¼¼
            total_ret = (val_exit / value_entry - 1.0)
        else:
            # ç„¡æ—¥æœŸäº‹ä»¶ï¼šå›é€€åˆ°è¿‘ä¼¼è™•ç†ï¼ˆåƒ…æœŸæœ«åŠ ç¸½è‚¡åˆ©èˆ‡è‚¡ç¥¨è‚¡åˆ©ï¼‰
            # ç›®æ¨™åœåˆ©åƒ¹/åœæåƒ¹ï¼ˆç›¸å°é€²å ´ï¼‰
            sl_thr = (entry_p * (1.0 - float(sl_pct))) if (sl_pct is not None and entry_p>0) else None
            tp_thr = (entry_p * (1.0 + float(tp_pct))) if (tp_pct is not None and entry_p>0) else None
            rolling_high = entry_p
            for i in range(1, len(g)):
                px = float(g['close_price'].iloc[i])
                d = g['date'].iloc[i]
                rolling_high = max(rolling_high, px)
                hits = []
                if sl_thr is not None and px <= sl_thr:
                    hits.append(('åœæ', d, px))
                if tp_thr is not None and px >= tp_thr:
                    hits.append(('åœåˆ©', d, px))
                if tsl_pct is not None and rolling_high>0 and px <= rolling_high * (1.0 - float(tsl_pct)):
                    hits.append(('ç§»å‹•åœæ', d, px))
                if not hits:
                    continue
                if trigger_priority == 'tp_first':
                    order = {'åœåˆ©':0,'åœæ':1,'ç§»å‹•åœæ':2}
                elif trigger_priority == 'sl_first':
                    order = {'åœæ':0,'åœåˆ©':1,'ç§»å‹•åœæ':2}
                else:
                    order = {'åœæ':0,'åœåˆ©':1,'ç§»å‹•åœæ':2}
                hits.sort(key=lambda x: order.get(x[0], 99))
                exit_reason, exit_date, exit_p = hits[0]
                break
            raw_ret = (exit_p/entry_p - 1.0) if (entry_p>0 and exit_p>0) else np.nan
            cash_div = 0.0
            stock_ratio_agg = 0.0
            if include_dividends:
                if exit_reason == 'æœŸæœ«':
                    cash_div = float(div_df[div_df['stock_id']==str(sid)]['cash_div_ps'].sum()) if not div_df.empty else 0.0
                    stock_ratio_agg = float(div_df[div_df['stock_id']==str(sid)]['stock_ratio_total'].sum()) if 'stock_ratio_total' in div_df.columns else 0.0
                else:
                    cash_div = 0.0
                    stock_ratio_agg = 0.0
            adj_exit_p = exit_p * (1.0 + stock_ratio_agg)
            total_ret = ((adj_exit_p - entry_p + cash_div) / entry_p) if entry_p>0 else np.nan
        out_rows.append([
            str(sid), int(trading_year), entry_date.date().isoformat(), exit_date.date().isoformat(),
            entry_p, exit_p, raw_ret, cash_div, total_ret, exit_reason
        ])
    return pd.DataFrame(out_rows, columns=['stock_id','year','entry_date','exit_date','entry_price','exit_price','raw_return','cash_div','total_return','exit_reason'])


def run_equal_weight_backtest(db_path: str,
                              profile: str = 'conservative',
                              dynamic: bool = False,
                              include_dividends: bool = True,
                              sl_pct: float | None = 0.15,
                              tp_pct: float | None = None,
                              tsl_pct: float | None = None,
                              trigger_priority: str = 'chronological',
                              initial_capital: float = 1_000_000.0) -> Dict:
    """å¹´åº¦ç­‰æ¬Šé‡å†å¹³è¡¡å›æ¸¬ï¼ˆè³‡é‡‘æ¨¡æ“¬ç‰ˆï¼‰ã€‚
    - dynamic=Falseï¼šä½¿ç”¨ç•¶å‰æ¸…å–® Top Nï¼ˆéœæ…‹åå–®ï¼‰
    - dynamic=Trueï¼šä½¿ç”¨æ¸…å–®æ­·å²ï¼Œæ¯å¹´ä»¥è©²å¹´çš„ Top Nï¼ˆå‹•æ…‹å†æ§‹æˆï¼‰
    - include_dividendsï¼šæ˜¯å¦å°‡ç•¶å¹´è‚¡åˆ©ï¼ˆç¾é‡‘èˆ‡è‚¡ç¥¨ï¼‰è¨ˆå…¥å ±é…¬
    - sl_pct/tp_pct/tsl_pctï¼šå›ºå®šåœæ/åœåˆ©/ç§»å‹•åœæç™¾åˆ†æ¯”ï¼ˆ0.15=15%ï¼‰
    - initial_capitalï¼šæœŸåˆè³‡é‡‘ï¼ˆé è¨­ 100 è¬ï¼‰
    è³‡é‡‘é…ç½®ï¼šæ¯å¹´ç­‰è³‡é‡‘é…ç½®åˆ°ç•¶å¹´çš„æŒè‚¡ï¼Œæå‰å‡ºå ´å¾Œè³‡é‡‘ä¸å†æŠ•å…¥ï¼ˆç•™ç¾é‡‘ï¼‰ã€‚
    è¼¸å‡ºä¸­æ–‡æ¬„ä½ CSV èˆ‡ JSON æ‘˜è¦ã€‚
    """
    # ç”¢æ¥­/å…¬å¸è³‡æ–™ï¼ˆå…©ç¨®æ¨¡å¼éƒ½æœƒç”¨åˆ°ï¼‰
    with get_conn(db_path) as conn:
        # å˜—è©¦è®€å– stocks åŸºæœ¬æ¬„ä½ï¼Œè‹¥ç¼ºæ¬„ä½å‰‡ä»¥ç©ºå­—ä¸²è£œä¸Š
        try:
            stocks_meta = pd.read_sql_query("SELECT stock_id, stock_name, industry FROM stocks", conn)
        except Exception:
            stocks_meta = pd.read_sql_query("SELECT stock_id FROM stocks", conn)
            stocks_meta['stock_name'] = ''
            stocks_meta['industry'] = ''
    # çµ±ä¸€è‚¡ç¥¨ä»£ç¢¼å‹åˆ¥ç‚ºå­—ä¸²ï¼Œé¿å… int/str åˆä½µéŒ¯èª¤
    if not stocks_meta.empty:
        stocks_meta['stock_id'] = stocks_meta['stock_id'].astype(str)
        if 'stock_name' not in stocks_meta.columns:
            stocks_meta['stock_name'] = ''
        if 'industry' not in stocks_meta.columns:
            stocks_meta['industry'] = ''

    if dynamic:
        from .history import load_history
        hist = load_history(profile)
        if hist.empty:
            raise ValueError('æ‰¾ä¸åˆ°æ¸…å–®æ­·å²ï¼Œè«‹å…ˆä»¥æŒ‡å®šå¹´åº¦åŒ¯å‡ºæ¸…å–®ä¸¦å¯«å…¥æ­·å²')
        # æº–å‚™ (year -> DataFrame with stock_id, rank)
        # ç¢ºä¿ stock_id çš†ç‚ºå­—ä¸²
        hist['stock_id'] = hist['stock_id'].astype(str)
        year_map = {int(y): g.sort_values('rank')[['stock_id','rank']].reset_index(drop=True) for y, g in hist.groupby('year')}
        years_sorted = sorted(year_map.keys())
        # ä¾å¹´åº¦å–åƒ¹ã€è¨ˆç®—å¹´åº¦å ±é…¬ã€ç­‰æ¬Šèˆ‡æ˜ç´°
        records = []
        details_list = []
        with get_conn(db_path) as conn:
            for y in years_sorted:
                g = year_map[y]
                # åŒä¸€å¹´è‹¥æ­·å²æª”ä¸­åŒä¸€è‚¡ç¥¨é‡è¤‡å‡ºç¾ï¼Œä¿ç•™æ’åæœ€å‰è€…
                g = g.sort_values('rank').drop_duplicates('stock_id', keep='first')
                ids = g['stock_id'].tolist()
                if not ids:
                    continue
                # ä½¿ç”¨ã€Œéš”å¹´ã€çš„å ±é…¬ï¼šä»¥ y å¹´æ¸…å–®åœ¨ y+1 å¹´ä¸€é–‹å¹´è²·é€²ã€å¹´åº•è³£å‡º
                trading_year = y + 1
                q_marks = ','.join(['?']*len(ids))
                prices = pd.read_sql_query(
                    f"SELECT stock_id, date, close_price FROM stock_prices WHERE stock_id IN ({q_marks}) AND strftime('%Y', date)=?",
                    conn, params=(ids + [str(trading_year)])
                )
                if prices.empty:
                    continue
                # æ‡‰ç”¨åœæèˆ‡ï¼ˆå«æ¯ï¼‰å ±é…¬è¨ˆç®—
                perf_y = _apply_stoploss_and_dividends(prices, trading_year, include_dividends, sl_pct, conn, tp_pct=tp_pct, tsl_pct=tsl_pct, trigger_priority=trigger_priority)
                # è³‡é‡‘æ¨¡æ“¬ï¼šç­‰è³‡é‡‘åˆ†é…
                n = perf_y['stock_id'].nunique() if not perf_y.empty else 0
                cap_begin = initial_capital
                cap_alloc = (cap_begin / n) if n > 0 else 0.0
                cap_end = 0.0
                if n > 0:
                    for _, r in perf_y.iterrows():
                        entry_p = float(r['entry_price']) if pd.notna(r['entry_price']) else 0.0
                        cash_div = float(r['cash_div']) if pd.notna(r['cash_div']) else 0.0
                        total_ret = float(r['total_return']) if pd.notna(r['total_return']) else 0.0
                        # é‡‘é¡æ–¹å¼ï¼šcap_alloc * (1 + total_ret)
                        cap_end += cap_alloc * (1.0 + total_ret)
                port_ret = (cap_end/cap_begin - 1.0) if cap_begin>0 and n>0 else np.nan
                records.append([trading_year, port_ret, n, cap_begin, cap_end])
                rep_y = perf_y.merge(g, on='stock_id', how='left').merge(stocks_meta, on='stock_id', how='left')
                rep_y['selected'] = rep_y['rank'].notna()
                rep_y['year'] = trading_year
                details_list.append(rep_y)
        port = pd.DataFrame(records, columns=['year','å¹´åº¦å ±é…¬ç‡','æˆåˆ†è‚¡æ•¸','æœŸåˆè³‡é‡‘','æœŸæœ«è³‡é‡‘']).sort_values('year')
        rep = pd.concat(details_list, ignore_index=True) if details_list else pd.DataFrame(columns=['stock_id','year','entry_date','exit_date','entry_price','exit_price','raw_return','cash_div','total_return','rank','stock_name','industry','selected'])
    else:
        top_df = load_quality_list(profile)  # columns: stock_id, rank
        stock_ids = top_df['stock_id'].tolist()
        with get_conn(db_path) as conn:
            # åªæŠ“å–æ¸…å–®ä¸­çš„è‚¡ç¥¨æ”¶ç›¤åƒ¹
            q_marks = ','.join(['?'] * len(stock_ids))
            prices = pd.read_sql_query(
                f"SELECT stock_id, date, close_price FROM stock_prices WHERE stock_id IN ({q_marks})",
                conn, params=stock_ids
            )
        if prices.empty:
            raise ValueError('ç„¡è‚¡åƒ¹è³‡æ–™å¯ä¾›å›æ¸¬')
        # å€‹è‚¡å¹´åº¦å ±é…¬ï¼ˆå«åœæ/å«æ¯ï¼‰
        perf_all = []
        for y in sorted(pd.to_datetime(prices['date']).dt.year.unique()):
            prices_y = prices[pd.to_datetime(prices['date']).dt.year == y]
            with get_conn(db_path) as conn:
                perf_y = _apply_stoploss_and_dividends(prices_y, int(y), include_dividends, sl_pct, conn, tp_pct=tp_pct, tsl_pct=tsl_pct, trigger_priority=trigger_priority)
            perf_all.append(perf_y)
        rep = pd.concat(perf_all, ignore_index=True) if perf_all else pd.DataFrame()
        # åˆä½µæ’åèˆ‡åŸºæœ¬è³‡æ–™
        # ç¢ºä¿å­—ä¸²å‹åˆ¥ä¸€è‡´
        rep['stock_id'] = rep['stock_id'].astype(str)
        top_df['stock_id'] = top_df['stock_id'].astype(str)
        rep = rep.merge(top_df, on='stock_id', how='left')
        rep['selected'] = rep['rank'].notna()
        # æŠ•çµ„è³‡é‡‘æ¨¡æ“¬ï¼šæ¯å¹´ä»¥ initial_capital ç­‰è³‡é‡‘åˆ†é…åˆ°è©²å¹´æ‰€æœ‰æ¸…å–®è‚¡
        years_sorted = sorted(pd.to_datetime(prices['date']).dt.year.unique())
        records = []
        for y in years_sorted:
            perf_y = rep[rep['year']==int(y)]
            n = perf_y['stock_id'].nunique() if not perf_y.empty else 0
            cap_begin = initial_capital
            cap_alloc = (cap_begin / n) if n>0 else 0.0
            cap_end = 0.0
            if n>0:
                for _, r in perf_y.iterrows():
                    total_ret = float(r['total_return']) if pd.notna(r['total_return']) else 0.0
                    cap_end += cap_alloc * (1.0 + total_ret)
            port_ret = (cap_end/cap_begin - 1.0) if cap_begin>0 and n>0 else np.nan
            records.append([int(y), port_ret, n, cap_begin, cap_end])
        port = pd.DataFrame(records, columns=['year','å¹´åº¦å ±é…¬ç‡','æˆåˆ†è‚¡æ•¸','æœŸåˆè³‡é‡‘','æœŸæœ«è³‡é‡‘']).sort_values('year')

    # ä¸­æ–‡æ˜ç´°è¼¸å‡º
    rep = rep.merge(stocks_meta, on='stock_id', how='left')
    details = rep.rename(columns={
        'stock_id':'è‚¡ç¥¨ä»£ç¢¼', 'stock_name':'å…¬å¸åç¨±', 'industry':'ç”¢æ¥­åˆ¥',
        'year':'å¹´åº¦',
        'entry_date':'é€²å ´æ—¥', 'exit_date':'å‡ºå ´æ—¥',
        'entry_price':'é€²å ´åƒ¹', 'exit_price':'å‡ºå ´åƒ¹',
        'raw_return':'å¹´åº¦å ±é…¬ç‡(ä¸å«æ¯)', 'cash_div':'ç¾é‡‘è‚¡åˆ©åˆè¨ˆ', 'total_return':'å¹´åº¦å ±é…¬ç‡(å«æ¯)',
        'rank':'æ¸…å–®æ’å', 'selected':'æ˜¯å¦å…¥é¸', 'exit_reason':'å‡ºå ´ç†ç”±'
    })
    details['æ˜¯å¦å…¥é¸'] = details['æ˜¯å¦å…¥é¸'].map(lambda x: 'æ˜¯' if bool(x) else 'å¦')
    # é˜²æ­¢ç¼ºæ¬„ä½å ±éŒ¯ï¼Œè‹¥ç¼ºå…¬å¸åç¨±/ç”¢æ¥­åˆ¥å‰‡ä»¥ç©ºå­—ä¸²è£œä¸Š
    for col in ['å…¬å¸åç¨±','ç”¢æ¥­åˆ¥']:
        if col not in details.columns:
            details[col] = ''
    details = details[['å¹´åº¦','è‚¡ç¥¨ä»£ç¢¼','å…¬å¸åç¨±','ç”¢æ¥­åˆ¥','æ¸…å–®æ’å','é€²å ´æ—¥','å‡ºå ´æ—¥','é€²å ´åƒ¹','å‡ºå ´åƒ¹','å‡ºå ´ç†ç”±','å¹´åº¦å ±é…¬ç‡(ä¸å«æ¯)','ç¾é‡‘è‚¡åˆ©åˆè¨ˆ','å¹´åº¦å ±é…¬ç‡(å«æ¯)','æ˜¯å¦å…¥é¸']]
    details = details.sort_values(['å¹´åº¦','æ¸…å–®æ’å'])
    out_details = os.path.join(OUTPUT_DIR, 'backtest_portfolio_details.csv')
    safe_write_csv(out_details,
                   [[int(r['å¹´åº¦']), str(r['è‚¡ç¥¨ä»£ç¢¼']), (int(r['æ¸…å–®æ’å']) if pd.notna(r['æ¸…å–®æ’å']) else 0),
                     str(r['å…¬å¸åç¨±']) if pd.notna(r['å…¬å¸åç¨±']) else '',
                     str(r['ç”¢æ¥­åˆ¥']) if pd.notna(r['ç”¢æ¥­åˆ¥']) else '',
                     str(r['é€²å ´æ—¥']) if pd.notna(r['é€²å ´æ—¥']) else '',
                     str(r['å‡ºå ´æ—¥']) if pd.notna(r['å‡ºå ´æ—¥']) else '',
                     float(r['é€²å ´åƒ¹']) if pd.notna(r['é€²å ´åƒ¹']) else '',
                     float(r['å‡ºå ´åƒ¹']) if pd.notna(r['å‡ºå ´åƒ¹']) else '',
                     str(r['å‡ºå ´ç†ç”±']) if pd.notna(r['å‡ºå ´ç†ç”±']) else '',
                     float(r['å¹´åº¦å ±é…¬ç‡(ä¸å«æ¯)']) if pd.notna(r['å¹´åº¦å ±é…¬ç‡(ä¸å«æ¯)']) else '',
                     float(r['ç¾é‡‘è‚¡åˆ©åˆè¨ˆ']) if pd.notna(r['ç¾é‡‘è‚¡åˆ©åˆè¨ˆ']) else '',
                     float(r['å¹´åº¦å ±é…¬ç‡(å«æ¯)']) if pd.notna(r['å¹´åº¦å ±é…¬ç‡(å«æ¯)']) else '',
                     str(r['æ˜¯å¦å…¥é¸'])]
                    for _, r in details.iterrows()],
                   ['å¹´åº¦','è‚¡ç¥¨ä»£ç¢¼','å…¬å¸åç¨±','ç”¢æ¥­åˆ¥','æ¸…å–®æ’å','é€²å ´æ—¥','å‡ºå ´æ—¥','é€²å ´åƒ¹','å‡ºå ´åƒ¹','å‡ºå ´ç†ç”±','å¹´åº¦å ±é…¬ç‡(ä¸å«æ¯)','ç¾é‡‘è‚¡åˆ©åˆè¨ˆ','å¹´åº¦å ±é…¬ç‡(å«æ¯)','æ˜¯å¦å…¥é¸'])

    # æŠ•çµ„ç­‰æ¬Šï¼ˆå‹•æ…‹æ¨¡å¼å·²ç®—æ–¼å‰ï¼Œéœæ…‹æ¨¡å¼ä¸Šæ–¹å·²ç®—ï¼‰
    if dynamic:
        pass
    else:
        pass

    # ç´¯ç©å ±é…¬èˆ‡ç¸¾æ•ˆæŒ‡æ¨™ï¼ˆä»¥å«æ¯å ±é…¬ç‚ºä¸»ï¼‰
    port['ç´¯ç©å ±é…¬å€¼'] = (1.0 + port['å¹´åº¦å ±é…¬ç‡']).cumprod()
    years = len(port)
    cagr = float(port['ç´¯ç©å ±é…¬å€¼'].iloc[-1]) ** (1.0 / years) - 1.0 if years > 0 else 0.0
    # æœ€å¤§å›æ’¤
    cum = port['ç´¯ç©å ±é…¬å€¼']
    roll_max = cum.cummax()
    drawdown = (cum / roll_max) - 1.0
    mdd = float(drawdown.min()) if not drawdown.empty else 0.0
    # å‹ç‡ï¼ˆå¹´åº¦å ±é…¬ç‡ > 0 çš„æ¯”ä¾‹ï¼‰
    win_rate = float((port['å¹´åº¦å ±é…¬ç‡'] > 0).mean()) if years > 0 else 0.0

    # åŒ¯å‡º CSVï¼ˆä¸­æ–‡æ¬„ä½ï¼‰
    out_csv = os.path.join(OUTPUT_DIR, 'backtest_portfolio_report.csv')
    header = ['å¹´åº¦', 'æˆåˆ†è‚¡æ•¸', 'æœŸåˆè³‡é‡‘', 'æœŸæœ«è³‡é‡‘', 'å¹´åº¦å ±é…¬ç‡', 'ç´¯ç©å ±é…¬å€¼']
    rows = [
        [int(r['year']), int(r['æˆåˆ†è‚¡æ•¸']), int(round(float(r['æœŸåˆè³‡é‡‘']))), int(round(float(r['æœŸæœ«è³‡é‡‘']))), float(r['å¹´åº¦å ±é…¬ç‡']), float(r['ç´¯ç©å ±é…¬å€¼'])]
        for _, r in port.iterrows()
    ]
    safe_write_csv(out_csv, rows, header)

    # åŒ¯å‡ºæ‘˜è¦ JSON
    summary = {
        'profile': profile,
        'years': years,
        'annualized_return': cagr,   # å¹´åŒ–å ±é…¬ç‡
        'max_drawdown': mdd,         # æœ€å¤§å›æ’¤
        'win_rate': win_rate,        # å‹ç‡ï¼ˆæ¯”ä¾‹ï¼‰
    }
    out_json = os.path.join(OUTPUT_DIR, 'backtest_portfolio_summary.json')
    safe_write_json(out_json, summary)

    log(f"ğŸ“„ å·²è¼¸å‡ºå›æ¸¬å ±å‘Š: {out_csv}")
    log(f"ğŸ§¾ å·²è¼¸å‡ºå›æ¸¬æ‘˜è¦: {out_json}")

    return {'report_csv': out_csv, 'summary_json': out_json, 'summary': summary}

