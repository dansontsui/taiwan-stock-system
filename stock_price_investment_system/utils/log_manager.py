# -*- coding: utf-8 -*-
"""
æ—¥èªŒç®¡ç†å·¥å…·
ç”¨æ–¼æ‰¹é‡èª¿å„ªæ™‚æ§åˆ¶æ—¥èªŒå¤§å°èˆ‡è¼¸å‡º
"""

import os
import sys
import logging
import gzip
from datetime import datetime
from pathlib import Path
from typing import Optional


def _safe_setup_stdout():
    try:
        sys.stdout.reconfigure(encoding="utf-8", errors="ignore")  # type: ignore[attr-defined]
    except Exception:
        pass


def _p(msg: str):
    try:
        print(msg)
    except UnicodeEncodeError:
        try:
            sys.stdout.write(msg.encode("utf-8", "ignore").decode("utf-8", "ignore") + "\n")
        except Exception:
            pass


def set_cli_only_mode(enabled: bool = True):
    """
    è¨­å®šCLIå°ˆç”¨æ¨¡å¼ - ç¦ç”¨æ‰€æœ‰æ¨¡çµ„çš„æª”æ¡ˆæ—¥èªŒè¼¸å‡º

    Args:
        enabled: True=å•Ÿç”¨CLIå°ˆç”¨æ¨¡å¼ï¼ˆä¸è¨˜éŒ„æª”æ¡ˆï¼‰ï¼ŒFalse=æ¢å¾©æ­£å¸¸æ¨¡å¼
    """
    # ç²å–æ‰€æœ‰ç›¸é—œçš„logger
    loggers_to_modify = [
        'stock_price_investment_system.data.data_manager',
        'stock_price_investment_system.data.revenue_integration',
        'stock_price_investment_system.data.price_data',
        'stock_price_investment_system.price_models.feature_engineering',
        'stock_price_investment_system.price_models.stock_price_predictor',
        'stock_price_investment_system.price_models.holdout_backtester',
        'stock_price_investment_system.price_models.walk_forward_validator',
        'stock_price_investment_system.selector.candidate_pool_generator',
        'stock_price_investment_system',  # æ ¹logger
    ]

    for logger_name in loggers_to_modify:
        logger = logging.getLogger(logger_name)

        if enabled:
            # CLIå°ˆç”¨æ¨¡å¼ï¼šç§»é™¤æ‰€æœ‰æª”æ¡ˆè™•ç†å™¨ï¼Œåªä¿ç•™æ§åˆ¶å°è™•ç†å™¨
            handlers_to_remove = []
            for handler in logger.handlers:
                if isinstance(handler, logging.FileHandler):
                    handlers_to_remove.append(handler)

            for handler in handlers_to_remove:
                logger.removeHandler(handler)
                handler.close()

            # è¨­å®šç‚ºä¸å‚³æ’­åˆ°çˆ¶loggerï¼ˆé¿å…é‡è¤‡è¼¸å‡ºï¼‰
            logger.propagate = False

            # å¦‚æœæ²’æœ‰æ§åˆ¶å°è™•ç†å™¨ï¼Œæ·»åŠ ä¸€å€‹ç°¡å–®çš„
            has_console_handler = any(
                isinstance(h, logging.StreamHandler) and h.stream == sys.stdout
                for h in logger.handlers
            )

            if not has_console_handler and logger.level <= logging.WARNING:
                # åªç‚ºè­¦å‘Šå’ŒéŒ¯èª¤æ·»åŠ æ§åˆ¶å°è™•ç†å™¨
                console_handler = logging.StreamHandler(sys.stdout)
                console_handler.setLevel(logging.WARNING)  # åªé¡¯ç¤ºè­¦å‘Šå’ŒéŒ¯èª¤
                formatter = logging.Formatter('%(levelname)s: %(message)s')
                console_handler.setFormatter(formatter)
                logger.addHandler(console_handler)
        else:
            # æ¢å¾©æ­£å¸¸æ¨¡å¼ï¼šé‡æ–°å•Ÿç”¨å‚³æ’­
            logger.propagate = True


def suppress_verbose_logging():
    """æŠ‘åˆ¶è©³ç´°çš„INFOç´šåˆ¥æ—¥èªŒï¼Œåªä¿ç•™WARNINGå’ŒERROR"""
    loggers_to_suppress = [
        'stock_price_investment_system.data.data_manager',
        'stock_price_investment_system.data.revenue_integration',
        'stock_price_investment_system.data.price_data',
        'stock_price_investment_system.price_models.feature_engineering',
    ]

    for logger_name in loggers_to_suppress:
        logger = logging.getLogger(logger_name)
        logger.setLevel(logging.WARNING)  # åªé¡¯ç¤ºWARNINGå’ŒERROR


def suppress_repetitive_warnings():
    """æŠ‘åˆ¶é‡è¤‡çš„WARNINGè¨Šæ¯ï¼Œç‰¹åˆ¥æ˜¯ç‡Ÿæ”¶/EPSé æ¸¬å™¨ä¸å¯ç”¨çš„è­¦å‘Š"""
    import warnings

    # æŠ‘åˆ¶ç‰¹å®šçš„é‡è¤‡è­¦å‘Š
    warnings.filterwarnings("ignore", message=".*Revenue predictor not available.*")
    warnings.filterwarnings("ignore", message=".*EPS predictor not available.*")

    # å‰µå»ºä¸€å€‹é€šç”¨çš„é‡è¤‡è­¦å‘Šéæ¿¾å™¨
    class RepetitiveWarningFilter(logging.Filter):
        def __init__(self):
            super().__init__()
            self.seen_messages = set()
            self.max_repeats = 1  # æ¯ç¨®è¨Šæ¯æœ€å¤šé¡¯ç¤º1æ¬¡

        def filter(self, record):
            try:
                if record.levelno == logging.WARNING:
                    # å®‰å…¨åœ°ç²å–è¨Šæ¯
                    try:
                        message = record.getMessage()
                    except (TypeError, AttributeError) as e:
                        # å¦‚æœgetMessage()å¤±æ•—ï¼Œå˜—è©¦ç›´æ¥ä½¿ç”¨msg
                        message = str(getattr(record, 'msg', ''))
                        if not message:
                            # å¦‚æœé‚„æ˜¯æ²’æœ‰è¨Šæ¯ï¼Œå…è¨±é€šéä½†è¨˜éŒ„å•é¡Œ
                            print(f"âš ï¸  æ—¥èªŒè¨˜éŒ„æ ¼å¼ç•°å¸¸: {e}")
                            return True

                    # æª¢æŸ¥æ˜¯å¦ç‚ºéœ€è¦æŠ‘åˆ¶çš„é‡è¤‡è­¦å‘Š
                    suppress_patterns = [
                        "predictor not available",
                        "æŸ¥ç„¡.*åƒ¹æ ¼è³‡æ–™",
                        "No price data available",
                        "No monthly revenue data found",
                        "No revenue data available",
                        "åƒ¹æ ¼è³‡æ–™ç¼ºå°‘å¿…è¦æ¬„ä½",
                        "Missing required columns",
                        "è³‡æ–™ç‚ºç©º",
                        "Empty data"
                    ]

                    should_suppress = any(pattern in message for pattern in suppress_patterns)

                    if should_suppress:
                        if message in self.seen_messages:
                            return False  # æŠ‘åˆ¶é‡è¤‡è¨Šæ¯
                        else:
                            self.seen_messages.add(message)
                            # ä¿®æ”¹è¨Šæ¯ï¼Œæ·»åŠ æç¤º
                            try:
                                record.msg = f"{record.msg} (å¾ŒçºŒç›¸åŒè­¦å‘Šå°‡è¢«æŠ‘åˆ¶)"
                            except (TypeError, AttributeError):
                                # å¦‚æœç„¡æ³•ä¿®æ”¹msgï¼Œå°±ä¸ä¿®æ”¹
                                pass
                            return True
            except Exception as e:
                # å¦‚æœéæ¿¾å™¨æœ¬èº«å‡ºéŒ¯ï¼Œå…è¨±æ—¥èªŒé€šéä¸¦è¨˜éŒ„å•é¡Œ
                print(f"âš ï¸  æ—¥èªŒéæ¿¾å™¨éŒ¯èª¤: {e}")
                return True
            return True

    # ç‚ºç›¸é—œæ¨¡çµ„æ·»åŠ éæ¿¾å™¨
    modules_to_filter = [
        'stock_price_investment_system.data.revenue_integration',
        'stock_price_investment_system.data.data_manager',
        'stock_price_investment_system.data.price_data',
        'stock_price_investment_system.price_models.feature_engineering'
    ]

    for module_name in modules_to_filter:
        logger = logging.getLogger(module_name)
        logger.addFilter(RepetitiveWarningFilter())


def suppress_data_missing_warnings():
    """å®Œå…¨æŠ‘åˆ¶è³‡æ–™ç¼ºå¤±ç›¸é—œçš„WARNINGè¨Šæ¯ï¼ˆç”¨æ–¼ç²¾ç°¡æ¨¡å¼ï¼‰"""

    class DataMissingWarningFilter(logging.Filter):
        def filter(self, record):
            try:
                if record.levelno == logging.WARNING:
                    # å®‰å…¨åœ°ç²å–è¨Šæ¯
                    try:
                        message = record.getMessage()
                    except (TypeError, AttributeError) as e:
                        # å¦‚æœgetMessage()å¤±æ•—ï¼Œå˜—è©¦ç›´æ¥ä½¿ç”¨msg
                        message = str(getattr(record, 'msg', ''))
                        if not message:
                            # å¦‚æœé‚„æ˜¯æ²’æœ‰è¨Šæ¯ï¼Œå…è¨±é€šéä½†è¨˜éŒ„å•é¡Œ
                            print(f"âš ï¸  æ—¥èªŒè¨˜éŒ„æ ¼å¼ç•°å¸¸: {e}")
                            return True

                    # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼é€²è¡Œæ›´ç²¾ç¢ºçš„åŒ¹é…
                    import re
                    suppress_patterns = [
                        r"æŸ¥ç„¡.*åƒ¹æ ¼è³‡æ–™",
                        r"No price data available",
                        r"No monthly revenue data found",
                        r"No revenue data available",
                        r"åƒ¹æ ¼è³‡æ–™ç¼ºå°‘å¿…è¦æ¬„ä½",
                        r"Missing required columns",
                        r"è³‡æ–™ç‚ºç©º",
                        r"Empty data",
                        r".*predictor not available.*",
                        r"Revenue predictor not available.*",
                        r"EPS predictor not available.*"
                    ]

                    # å¦‚æœåŒ¹é…ä»»ä½•æ¨¡å¼ï¼Œå®Œå…¨æŠ‘åˆ¶
                    for pattern in suppress_patterns:
                        if re.search(pattern, message, re.IGNORECASE):
                            return False

            except Exception as e:
                # å¦‚æœéæ¿¾å™¨æœ¬èº«å‡ºéŒ¯ï¼Œå…è¨±æ—¥èªŒé€šéä¸¦è¨˜éŒ„å•é¡Œ
                print(f"âš ï¸  æ—¥èªŒéæ¿¾å™¨éŒ¯èª¤: {e}")
                return True

            return True

    # ç‚ºæ‰€æœ‰ç›¸é—œæ¨¡çµ„æ·»åŠ å¼·åŠ›éæ¿¾å™¨
    modules_to_filter = [
        'stock_price_investment_system.data.revenue_integration',
        'stock_price_investment_system.data.data_manager',
        'stock_price_investment_system.data.price_data',
        'stock_price_investment_system.price_models.feature_engineering',
        'stock_price_investment_system.price_models.stock_price_predictor',
        'stock_price_investment_system.price_models.holdout_backtester',
        'stock_price_investment_system.price_models.walk_forward_validator'
    ]

    for module_name in modules_to_filter:
        logger = logging.getLogger(module_name)
        logger.addFilter(DataMissingWarningFilter())


def log_menu_parameters(menu_id: str, menu_name: str, parameters: dict, force_log: bool = True):
    """
    è¨˜éŒ„é¸å–®åƒæ•¸åˆ°æ—¥èªŒæª”æ¡ˆ

    Args:
        menu_id: é¸å–®ç·¨è™Ÿ
        menu_name: é¸å–®åç¨±
        parameters: åƒæ•¸å­—å…¸
        force_log: æ˜¯å¦å¼·åˆ¶è¨˜éŒ„ï¼ˆå³ä½¿åœ¨CLIå°ˆç”¨æ¨¡å¼ä¸‹ï¼‰
    """
    import json
    from datetime import datetime
    from pathlib import Path

    try:
        # å‰µå»ºåƒæ•¸è¨˜éŒ„
        param_record = {
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'menu_id': menu_id,
            'menu_name': menu_name,
            'parameters': parameters
        }

        # ç¢ºä¿æ—¥èªŒç›®éŒ„å­˜åœ¨
        log_dir = Path("stock_price_investment_system/logs")
        log_dir.mkdir(parents=True, exist_ok=True)
        log_file = log_dir / "menu_parameters.log"

        # æ ¼å¼åŒ–åƒæ•¸è¨˜éŒ„
        param_str = json.dumps(param_record, ensure_ascii=False, indent=2)
        log_entry = f"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - é¸å–®åƒæ•¸è¨˜éŒ„:\n{param_str}\n\n"

        # ç›´æ¥å¯«å…¥æª”æ¡ˆï¼ˆè¿½åŠ æ¨¡å¼ï¼‰
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(log_entry)

        # åŒæ™‚è¼¸å‡ºåˆ°æ§åˆ¶å°
        print(f"ğŸ“ å·²è¨˜éŒ„é¸å–®{menu_id}çš„åƒæ•¸åˆ°æ—¥èªŒæª”æ¡ˆ")

    except Exception as e:
        print(f"âš ï¸  åƒæ•¸è¨˜éŒ„å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()


def log_execution_summary(menu_id: str, menu_name: str, success: bool, duration: float = None, result_summary: str = None):
    """
    è¨˜éŒ„åŸ·è¡Œæ‘˜è¦åˆ°æ—¥èªŒæª”æ¡ˆ

    Args:
        menu_id: é¸å–®ç·¨è™Ÿ
        menu_name: é¸å–®åç¨±
        success: æ˜¯å¦åŸ·è¡ŒæˆåŠŸ
        duration: åŸ·è¡Œæ™‚é–“ï¼ˆç§’ï¼‰
        result_summary: çµæœæ‘˜è¦
    """
    from datetime import datetime
    from pathlib import Path

    try:
        # ç¢ºä¿æ—¥èªŒç›®éŒ„å­˜åœ¨
        log_dir = Path("stock_price_investment_system/logs")
        log_dir.mkdir(parents=True, exist_ok=True)
        log_file = log_dir / "menu_parameters.log"

        status = "æˆåŠŸ" if success else "å¤±æ•—"
        duration_str = f", è€—æ™‚: {duration:.1f}ç§’" if duration else ""

        log_message = f"é¸å–®{menu_id}åŸ·è¡Œ{status}{duration_str}"
        if result_summary:
            log_message += f", çµæœ: {result_summary}"

        # ç›´æ¥å¯«å…¥æª”æ¡ˆï¼ˆè¿½åŠ æ¨¡å¼ï¼‰
        log_entry = f"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - {log_message}\n"
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(log_entry)

        # åŒæ™‚è¼¸å‡ºåˆ°æ§åˆ¶å°
        emoji = "âœ…" if success else "âŒ"
        print(f"{emoji} {log_message}")

    except Exception as e:
        print(f"âš ï¸  åŸ·è¡Œæ‘˜è¦è¨˜éŒ„å¤±æ•—: {e}")


class BatchLogManager:
    """æ‰¹é‡èª¿å„ªå°ˆç”¨çš„æ—¥èªŒç®¡ç†å™¨"""
    
    def __init__(self, log_mode: str = "2", max_log_size_mb: int = 50):
        """
        åˆå§‹åŒ–æ—¥èªŒç®¡ç†å™¨
        
        Args:
            log_mode: æ—¥èªŒæ¨¡å¼ ("1"=æ¨™æº–, "2"=ç°¡åŒ–, "3"=éœé»˜)
            max_log_size_mb: æ—¥èªŒæª”æ¡ˆå¤§å°ä¸Šé™ï¼ˆMBï¼‰
        """
        self.log_mode = log_mode
        self.max_log_size = max_log_size_mb * 1024 * 1024  # è½‰æ›ç‚º bytes
        self.original_log_level = None
        self.batch_log_file = None
        
        _safe_setup_stdout()
    
    def start_batch_logging(self, operation_name: str = "batch_tuning"):
        """é–‹å§‹æ‰¹é‡æ“ä½œçš„æ—¥èªŒè¨˜éŒ„"""
        # è¨­å®šæ—¥èªŒç´šåˆ¥
        if self.log_mode == '3':  # éœé»˜æ¨¡å¼
            self.original_log_level = logging.getLogger().level
            logging.getLogger().setLevel(logging.ERROR)
            logging.getLogger('stock_price_investment_system').setLevel(logging.ERROR)
        elif self.log_mode == '2':  # ç°¡åŒ–æ¨¡å¼
            self.original_log_level = logging.getLogger().level
            logging.getLogger().setLevel(logging.WARNING)
            logging.getLogger('stock_price_investment_system').setLevel(logging.WARNING)
        
        # å‰µå»ºå°ˆç”¨çš„æ‰¹é‡æ—¥èªŒæª”æ¡ˆ
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        log_dir = Path("stock_price_investment_system/logs")
        log_dir.mkdir(exist_ok=True)
        
        self.batch_log_file = log_dir / f"{operation_name}_{timestamp}.log"
        
        # è¨­å®šæ‰¹é‡æ—¥èªŒè™•ç†å™¨
        batch_handler = logging.FileHandler(self.batch_log_file, encoding='utf-8')
        batch_formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        batch_handler.setFormatter(batch_formatter)
        
        # åªåœ¨ç°¡åŒ–/éœé»˜æ¨¡å¼ä¸‹ä½¿ç”¨å°ˆç”¨æ—¥èªŒæª”æ¡ˆ
        if self.log_mode in ['2', '3']:
            # ç§»é™¤ç¾æœ‰çš„æª”æ¡ˆè™•ç†å™¨ï¼Œåªä¿ç•™æ‰¹é‡è™•ç†å™¨
            logger = logging.getLogger()
            for handler in logger.handlers[:]:
                if isinstance(handler, logging.FileHandler):
                    logger.removeHandler(handler)
            logger.addHandler(batch_handler)
        
        _p(f"ğŸ“ æ‰¹é‡æ—¥èªŒæ¨¡å¼: {['æ¨™æº–', 'ç°¡åŒ–', 'éœé»˜'][int(self.log_mode)-1]}")
        _p(f"ğŸ“ æ‰¹é‡æ—¥èªŒæª”æ¡ˆ: {self.batch_log_file}")
    
    def stop_batch_logging(self):
        """çµæŸæ‰¹é‡æ“ä½œçš„æ—¥èªŒè¨˜éŒ„"""
        # æ¢å¾©åŸå§‹æ—¥èªŒç´šåˆ¥
        if self.original_log_level is not None:
            logging.getLogger().setLevel(self.original_log_level)
            logging.getLogger('stock_price_investment_system').setLevel(self.original_log_level)
        
        # æª¢æŸ¥æ—¥èªŒæª”æ¡ˆå¤§å°
        if self.batch_log_file and self.batch_log_file.exists():
            file_size = self.batch_log_file.stat().st_size
            size_mb = file_size / (1024 * 1024)
            
            _p(f"ğŸ“Š æ‰¹é‡æ—¥èªŒæª”æ¡ˆå¤§å°: {size_mb:.1f} MB")
            
            # å¦‚æœæª”æ¡ˆå¤ªå¤§ï¼Œæä¾›å£“ç¸®é¸é …
            if file_size > self.max_log_size:
                _p(f"âš ï¸  æ—¥èªŒæª”æ¡ˆè¶…é {self.max_log_size/(1024*1024):.0f} MB é™åˆ¶")
                
                try:
                    compressed_file = self.batch_log_file.with_suffix('.log.gz')
                    with open(self.batch_log_file, 'rb') as f_in:
                        with gzip.open(compressed_file, 'wb') as f_out:
                            f_out.writelines(f_in)
                    
                    # åˆªé™¤åŸå§‹æª”æ¡ˆ
                    self.batch_log_file.unlink()
                    
                    compressed_size = compressed_file.stat().st_size / (1024 * 1024)
                    _p(f"âœ… å·²å£“ç¸®æ—¥èªŒæª”æ¡ˆ: {compressed_file} ({compressed_size:.1f} MB)")
                    
                except Exception as e:
                    _p(f"âŒ å£“ç¸®æ—¥èªŒæª”æ¡ˆå¤±æ•—: {e}")
    
    def log_progress(self, current: int, total: int, successful: int, failed: int, 
                    stock_id: Optional[str] = None, result: Optional[str] = None):
        """è¨˜éŒ„é€²åº¦è¨Šæ¯"""
        if self.log_mode == '1':  # æ¨™æº–æ¨¡å¼
            if stock_id and result:
                _p(f"ğŸ“Š [{current}/{total}] {stock_id}: {result}")
        elif self.log_mode == '2':  # ç°¡åŒ–æ¨¡å¼
            if current % 10 == 1 or current == total:
                if stock_id:
                    _p(f"ğŸ“Š è™•ç†è‚¡ç¥¨ {current}-{min(current+9, total)}: {stock_id}...")
        elif self.log_mode == '3':  # éœé»˜æ¨¡å¼
            if current % 100 == 0 or current == total:
                _p(f"ğŸ“ˆ é€²åº¦: {current}/{total} (æˆåŠŸ: {successful}, å¤±æ•—: {failed})")
    
    def log_summary(self, current: int, total: int, successful: int, failed: int):
        """è¨˜éŒ„æ‘˜è¦è¨Šæ¯"""
        show_summary = False
        
        if self.log_mode == '1' and (current % 10 == 0 or current == total):
            show_summary = True
        elif self.log_mode == '2' and (current % 50 == 0 or current == total):
            show_summary = True
        elif self.log_mode == '3' and (current % 100 == 0 or current == total):
            show_summary = True
        
        if show_summary:
            _p(f"ğŸ“ˆ é€²åº¦æ‘˜è¦ [{current}/{total}]: æˆåŠŸ {successful}, å¤±æ•— {failed}")


def clean_old_logs(log_dir: str = "stock_price_investment_system/logs", 
                   keep_days: int = 7, 
                   compress_days: int = 1):
    """
    æ¸…ç†èˆŠæ—¥èªŒæª”æ¡ˆ
    
    Args:
        log_dir: æ—¥èªŒç›®éŒ„
        keep_days: ä¿ç•™å¤©æ•¸
        compress_days: è¶…éå¹¾å¤©çš„æª”æ¡ˆé€²è¡Œå£“ç¸®
    """
    _safe_setup_stdout()
    
    log_path = Path(log_dir)
    if not log_path.exists():
        return
    
    now = datetime.now()
    compressed_count = 0
    deleted_count = 0
    
    for log_file in log_path.glob("*.log"):
        # è·³éç•¶å‰æœƒè©±çš„æ—¥èªŒ
        if "current_session" in log_file.name:
            continue
            
        file_age = (now - datetime.fromtimestamp(log_file.stat().st_mtime)).days
        
        if file_age > keep_days:
            # åˆªé™¤èˆŠæª”æ¡ˆ
            try:
                log_file.unlink()
                deleted_count += 1
            except Exception as e:
                _p(f"âŒ åˆªé™¤æ—¥èªŒæª”æ¡ˆå¤±æ•— {log_file}: {e}")
                
        elif file_age > compress_days and not log_file.name.endswith('.gz'):
            # å£“ç¸®æª”æ¡ˆ
            try:
                compressed_file = log_file.with_suffix('.log.gz')
                with open(log_file, 'rb') as f_in:
                    with gzip.open(compressed_file, 'wb') as f_out:
                        f_out.writelines(f_in)
                
                log_file.unlink()
                compressed_count += 1
            except Exception as e:
                _p(f"âŒ å£“ç¸®æ—¥èªŒæª”æ¡ˆå¤±æ•— {log_file}: {e}")
    
    if compressed_count > 0 or deleted_count > 0:
        _p(f"ğŸ§¹ æ—¥èªŒæ¸…ç†å®Œæˆ: å£“ç¸® {compressed_count} å€‹, åˆªé™¤ {deleted_count} å€‹æª”æ¡ˆ")


# ä½¿ç”¨ç¯„ä¾‹
if __name__ == "__main__":
    # æ¸¬è©¦æ—¥èªŒç®¡ç†å™¨
    manager = BatchLogManager(log_mode="2")
    manager.start_batch_logging("test_operation")
    
    # æ¨¡æ“¬æ‰¹é‡æ“ä½œ
    total_stocks = 100
    successful = 0
    failed = 0
    
    for i in range(1, total_stocks + 1):
        stock_id = f"TEST{i:04d}"
        
        # æ¨¡æ“¬è™•ç†çµæœ
        if i % 7 == 0:  # æ¨¡æ“¬å¤±æ•—
            failed += 1
            result = "âŒ å¤±æ•—"
        else:
            successful += 1
            result = "âœ… æˆåŠŸ"
        
        manager.log_progress(i, total_stocks, successful, failed, stock_id, result)
        manager.log_summary(i, total_stocks, successful, failed)
    
    manager.stop_batch_logging()
    
    # æ¸…ç†èˆŠæ—¥èªŒ
    clean_old_logs()
