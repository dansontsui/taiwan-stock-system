# -*- coding: utf-8 -*-
"""
EPS Revenue Predictor - Model Optimizer
AIæ¨¡å‹å„ªåŒ–å™¨ - åŸºæ–¼å›æ¸¬çµæœèª¿æ•´æ¨¡å‹åƒæ•¸
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Tuple
import json
from datetime import datetime
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

try:
    from lightgbm import LGBMRegressor
    LIGHTGBM_AVAILABLE = True
except ImportError:
    from sklearn.ensemble import GradientBoostingRegressor
    LIGHTGBM_AVAILABLE = False

from sklearn.model_selection import GridSearchCV, cross_val_score
from sklearn.preprocessing import StandardScaler
import joblib

from config.settings import PROJECT_ROOT, AI_MODEL_CONFIG
from src.data.database_manager import DatabaseManager
from src.models.adjustment_model import AIAdjustmentModel
from src.utils.logger import get_logger, log_execution
from src.utils.accuracy_metrics import AccuracyMetrics

logger = get_logger('model_optimizer')

class ModelOptimizer:
    """AIæ¨¡å‹å„ªåŒ–å™¨
    
    åŸºæ–¼å›æ¸¬çµæœè‡ªå‹•èª¿æ•´AIæ¨¡å‹åƒæ•¸å’Œæ¬Šé‡
    """
    
    def __init__(self, db_manager: DatabaseManager = None):
        self.db_manager = db_manager or DatabaseManager()
        self.ai_model = AIAdjustmentModel(self.db_manager)
        self.accuracy_metrics = AccuracyMetrics()
        
        # å„ªåŒ–æ­·å²è¨˜éŒ„
        self.optimization_history_path = PROJECT_ROOT / 'models' / 'optimization_history.json'
        self.optimization_history_path.parent.mkdir(parents=True, exist_ok=True)
        
        logger.info("ModelOptimizer initialized")
    
    @log_execution
    def optimize_based_on_backtest(self, stock_id: str, backtest_results: Dict) -> Dict:
        """
        åŸºæ–¼å›æ¸¬çµæœå„ªåŒ–æ¨¡å‹
        
        Args:
            stock_id: è‚¡ç¥¨ä»£ç¢¼
            backtest_results: å›æ¸¬çµæœ
            
        Returns:
            å„ªåŒ–çµæœå­—å…¸
        """
        logger.info(f"Starting model optimization for {stock_id} based on backtest results")
        
        try:
            optimization_result = {
                'stock_id': stock_id,
                'optimization_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'optimizations_applied': [],
                'performance_before': {},
                'performance_after': {},
                'recommendations': []
            }
            
            # åˆ†æå›æ¸¬çµæœ
            analysis = self._analyze_backtest_performance(backtest_results)
            optimization_result['performance_before'] = analysis
            
            # æ±ºå®šå„ªåŒ–ç­–ç•¥
            optimization_strategies = self._determine_optimization_strategies(analysis)
            
            # åŸ·è¡Œå„ªåŒ–
            for strategy in optimization_strategies:
                logger.info(f"Applying optimization strategy: {strategy['type']}")
                
                strategy_result = self._apply_optimization_strategy(
                    stock_id, strategy, backtest_results
                )
                
                optimization_result['optimizations_applied'].append(strategy_result)
            
            # ç”Ÿæˆå»ºè­°
            recommendations = self._generate_optimization_recommendations(analysis)
            optimization_result['recommendations'] = recommendations
            
            # è¨˜éŒ„å„ªåŒ–æ­·å²
            self._save_optimization_history(optimization_result)
            
            logger.info(f"Model optimization completed for {stock_id}")
            return optimization_result
            
        except Exception as e:
            logger.error(f"Model optimization failed for {stock_id}: {e}")
            return {
                'stock_id': stock_id,
                'error': str(e),
                'optimization_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
    
    def _analyze_backtest_performance(self, backtest_results: Dict) -> Dict:
        """åˆ†æå›æ¸¬è¡¨ç¾"""
        try:
            analysis = {
                'revenue_performance': {},
                'eps_performance': {},
                'overall_assessment': {},
                'problem_areas': []
            }
            
            # ç‡Ÿæ”¶è¡¨ç¾åˆ†æ
            revenue_results = backtest_results.get('results', {}).get('revenue', {})
            if revenue_results.get('success'):
                revenue_stats = revenue_results.get('statistics', {})
                analysis['revenue_performance'] = {
                    'direction_accuracy': revenue_stats.get('direction_accuracy', 0),
                    'mape': revenue_stats.get('avg_revenue_mape', 0),
                    'rmse': revenue_stats.get('rmse_growth', 0),
                    'periods_tested': revenue_stats.get('total_periods', 0)
                }
                
                # è­˜åˆ¥å•é¡Œ
                if revenue_stats.get('direction_accuracy', 0) < 0.6:
                    analysis['problem_areas'].append('revenue_direction_accuracy')
                if revenue_stats.get('avg_revenue_mape', 0) > 15:
                    analysis['problem_areas'].append('revenue_magnitude_error')
            
            # EPSè¡¨ç¾åˆ†æ
            eps_results = backtest_results.get('results', {}).get('eps', {})
            if eps_results.get('success'):
                eps_stats = eps_results.get('statistics', {})
                analysis['eps_performance'] = {
                    'direction_accuracy': eps_stats.get('direction_accuracy', 0),
                    'mape': eps_stats.get('avg_eps_mape', 0),
                    'rmse': eps_stats.get('rmse_growth', 0),
                    'periods_tested': eps_stats.get('total_periods', 0)
                }
                
                # è­˜åˆ¥å•é¡Œ
                if eps_stats.get('direction_accuracy', 0) < 0.6:
                    analysis['problem_areas'].append('eps_direction_accuracy')
                if eps_stats.get('avg_eps_mape', 0) > 20:
                    analysis['problem_areas'].append('eps_magnitude_error')
            
            # æ•´é«”è©•ä¼°
            overall_stats = backtest_results.get('overall_statistics', {})
            combined_perf = overall_stats.get('combined_performance', {})
            
            if combined_perf:
                analysis['overall_assessment'] = {
                    'combined_direction_accuracy': combined_perf.get('avg_direction_accuracy', 0),
                    'total_predictions': combined_perf.get('total_predictions', 0),
                    'needs_optimization': combined_perf.get('avg_direction_accuracy', 0) < 0.65
                }
            
            return analysis
            
        except Exception as e:
            logger.warning(f"Failed to analyze backtest performance: {e}")
            return {}
    
    def _determine_optimization_strategies(self, analysis: Dict) -> List[Dict]:
        """æ±ºå®šå„ªåŒ–ç­–ç•¥"""
        strategies = []
        problem_areas = analysis.get('problem_areas', [])
        
        # æ–¹å‘æº–ç¢ºåº¦å•é¡Œ
        if 'revenue_direction_accuracy' in problem_areas or 'eps_direction_accuracy' in problem_areas:
            strategies.append({
                'type': 'retrain_ai_model',
                'priority': 'high',
                'reason': 'Poor directional accuracy',
                'target': 'ai_adjustment_model'
            })
        
        # å¹…åº¦èª¤å·®å•é¡Œ
        if 'revenue_magnitude_error' in problem_areas or 'eps_magnitude_error' in problem_areas:
            strategies.append({
                'type': 'adjust_formula_weights',
                'priority': 'medium',
                'reason': 'High magnitude errors',
                'target': 'formula_weights'
            })
        
        # æ•´é«”è¡¨ç¾ä¸ä½³
        overall_needs_opt = analysis.get('overall_assessment', {}).get('needs_optimization', False)
        if overall_needs_opt:
            strategies.append({
                'type': 'hyperparameter_tuning',
                'priority': 'medium',
                'reason': 'Overall performance below threshold',
                'target': 'ai_model_hyperparameters'
            })
        
        # å¦‚æœæ²’æœ‰æ˜é¡¯å•é¡Œï¼Œé€²è¡Œå¾®èª¿
        if not strategies:
            strategies.append({
                'type': 'fine_tuning',
                'priority': 'low',
                'reason': 'Preventive optimization',
                'target': 'model_parameters'
            })
        
        # æŒ‰å„ªå…ˆç´šæ’åº
        priority_order = {'high': 3, 'medium': 2, 'low': 1}
        strategies.sort(key=lambda x: priority_order.get(x['priority'], 0), reverse=True)
        
        return strategies
    
    def _apply_optimization_strategy(self, stock_id: str, strategy: Dict, 
                                   backtest_results: Dict) -> Dict:
        """æ‡‰ç”¨å„ªåŒ–ç­–ç•¥"""
        strategy_type = strategy['type']
        
        try:
            if strategy_type == 'retrain_ai_model':
                return self._retrain_ai_model(stock_id)
            
            elif strategy_type == 'adjust_formula_weights':
                return self._adjust_formula_weights(stock_id, backtest_results)
            
            elif strategy_type == 'hyperparameter_tuning':
                return self._tune_hyperparameters(stock_id)
            
            elif strategy_type == 'fine_tuning':
                return self._fine_tune_model(stock_id)
            
            else:
                return {
                    'strategy': strategy_type,
                    'success': False,
                    'error': 'Unknown strategy type'
                }
                
        except Exception as e:
            logger.error(f"Failed to apply strategy {strategy_type}: {e}")
            return {
                'strategy': strategy_type,
                'success': False,
                'error': str(e)
            }
    
    def _retrain_ai_model(self, stock_id: str) -> Dict:
        """é‡æ–°è¨“ç·´AIæ¨¡å‹"""
        logger.info(f"Retraining AI model for {stock_id}")
        
        try:
            # é‡æ–°è¨“ç·´é€šç”¨AIæ¨¡å‹
            retrain_result = self.ai_model.train_model(retrain=True)
            
            # å¦‚æœå¯èƒ½ï¼Œè¨“ç·´è‚¡ç¥¨å°ˆç”¨æ¨¡å‹
            stock_specific_result = None
            try:
                # æª¢æŸ¥æ˜¯å¦æœ‰è¶³å¤ è³‡æ–™è¨“ç·´å°ˆç”¨æ¨¡å‹
                data_validation = self.db_manager.validate_backtest_data_availability(stock_id)
                if data_validation.get('backtest_feasible', False):
                    # é€™è£¡å¯ä»¥æ·»åŠ è‚¡ç¥¨å°ˆç”¨æ¨¡å‹è¨“ç·´é‚è¼¯
                    stock_specific_result = {'status': 'stock_specific_training_available'}
            except Exception as e:
                logger.warning(f"Stock-specific model training failed: {e}")
            
            return {
                'strategy': 'retrain_ai_model',
                'success': retrain_result.get('status') in ['success', 'loaded_existing'],
                'general_model_result': retrain_result,
                'stock_specific_result': stock_specific_result,
                'improvement_expected': 'Better directional accuracy'
            }
            
        except Exception as e:
            logger.error(f"AI model retraining failed: {e}")
            return {
                'strategy': 'retrain_ai_model',
                'success': False,
                'error': str(e)
            }
    
    def _adjust_formula_weights(self, stock_id: str, backtest_results: Dict) -> Dict:
        """èª¿æ•´è²¡å‹™å…¬å¼æ¬Šé‡"""
        logger.info(f"Adjusting formula weights for {stock_id}")
        
        try:
            # åˆ†æå„æ–¹æ³•çš„è¡¨ç¾
            revenue_results = backtest_results.get('results', {}).get('revenue', {}).get('backtest_results', [])
            eps_results = backtest_results.get('results', {}).get('eps', {}).get('backtest_results', [])
            
            weight_adjustments = {
                'revenue_weights': self._analyze_method_performance(revenue_results, 'revenue'),
                'eps_weights': self._analyze_method_performance(eps_results, 'eps')
            }
            
            # ä¿å­˜æ¬Šé‡èª¿æ•´å»ºè­°
            adjustment_file = PROJECT_ROOT / 'models' / f'weight_adjustments_{stock_id}.json'
            with open(adjustment_file, 'w', encoding='utf-8') as f:
                json.dump(weight_adjustments, f, ensure_ascii=False, indent=2)
            
            return {
                'strategy': 'adjust_formula_weights',
                'success': True,
                'weight_adjustments': weight_adjustments,
                'adjustment_file': str(adjustment_file),
                'improvement_expected': 'Better magnitude accuracy'
            }
            
        except Exception as e:
            logger.error(f"Formula weight adjustment failed: {e}")
            return {
                'strategy': 'adjust_formula_weights',
                'success': False,
                'error': str(e)
            }
    
    def _tune_hyperparameters(self, stock_id: str) -> Dict:
        """èª¿æ•´è¶…åƒæ•¸"""
        logger.info(f"Tuning hyperparameters for {stock_id}")
        
        try:
            # å®šç¾©è¶…åƒæ•¸æœç´¢ç©ºé–“
            if LIGHTGBM_AVAILABLE:
                param_grid = {
                    'n_estimators': [50, 100, 150],
                    'max_depth': [4, 6, 8],
                    'learning_rate': [0.05, 0.1, 0.15],
                    'num_leaves': [20, 31, 40]
                }
                base_model = LGBMRegressor(random_state=42, verbose=-1)
            else:
                param_grid = {
                    'n_estimators': [50, 100, 150],
                    'max_depth': [4, 6, 8],
                    'learning_rate': [0.05, 0.1, 0.15]
                }
                base_model = GradientBoostingRegressor(random_state=42)
            
            # ç²å–è¨“ç·´è³‡æ–™
            training_data = self._prepare_hyperparameter_tuning_data(stock_id)
            
            if training_data is None or len(training_data) < 10:
                return {
                    'strategy': 'hyperparameter_tuning',
                    'success': False,
                    'error': 'Insufficient training data'
                }
            
            X, y = training_data
            
            # åŸ·è¡Œç¶²æ ¼æœç´¢
            grid_search = GridSearchCV(
                base_model, param_grid, cv=3, scoring='neg_mean_squared_error',
                n_jobs=-1, verbose=0
            )
            
            grid_search.fit(X, y)
            
            # ä¿å­˜æœ€ä½³åƒæ•¸
            best_params_file = PROJECT_ROOT / 'models' / f'best_params_{stock_id}.json'
            with open(best_params_file, 'w', encoding='utf-8') as f:
                json.dump(grid_search.best_params_, f, ensure_ascii=False, indent=2)
            
            return {
                'strategy': 'hyperparameter_tuning',
                'success': True,
                'best_params': grid_search.best_params_,
                'best_score': grid_search.best_score_,
                'params_file': str(best_params_file),
                'improvement_expected': 'Better overall performance'
            }
            
        except Exception as e:
            logger.error(f"Hyperparameter tuning failed: {e}")
            return {
                'strategy': 'hyperparameter_tuning',
                'success': False,
                'error': str(e)
            }
    
    def _fine_tune_model(self, stock_id: str) -> Dict:
        """å¾®èª¿æ¨¡å‹"""
        logger.info(f"Fine-tuning model for {stock_id}")
        
        try:
            # å¾®èª¿ç­–ç•¥ï¼šèª¿æ•´AIèª¿æ•´ç¯„åœ
            current_range = AI_MODEL_CONFIG.get('adjustment_range', 0.2)
            
            # åŸºæ–¼æ­·å²è¡¨ç¾èª¿æ•´ç¯„åœ
            adjustment_suggestions = {
                'current_adjustment_range': current_range,
                'suggested_range': min(0.25, current_range * 1.1),  # ç•¥å¾®å¢åŠ èª¿æ•´ç¯„åœ
                'confidence_threshold_adjustment': 0.05,  # èª¿æ•´ä¿¡å¿ƒé–¾å€¼
                'feature_importance_rebalancing': True
            }
            
            return {
                'strategy': 'fine_tuning',
                'success': True,
                'adjustments': adjustment_suggestions,
                'improvement_expected': 'Marginal performance improvement'
            }
            
        except Exception as e:
            logger.error(f"Model fine-tuning failed: {e}")
            return {
                'strategy': 'fine_tuning',
                'success': False,
                'error': str(e)
            }

    def _analyze_method_performance(self, backtest_results: List[Dict],
                                  prediction_type: str) -> Dict:
        """åˆ†æå„é æ¸¬æ–¹æ³•çš„è¡¨ç¾"""
        try:
            method_performance = {}

            for result in backtest_results:
                prediction = result.get('prediction', {})
                method_breakdown = prediction.get('method_breakdown', {})
                accuracy = result.get('accuracy', {})

                # åˆ†æå„æ–¹æ³•çš„è²¢ç»
                for method_name, method_result in method_breakdown.items():
                    if method_name not in method_performance:
                        method_performance[method_name] = {
                            'errors': [],
                            'contributions': []
                        }

                    # è¨˜éŒ„èª¤å·®å’Œè²¢ç»
                    if prediction_type == 'revenue':
                        error = accuracy.get('revenue_mape', 0)
                    else:
                        error = accuracy.get('eps_mape', 0)

                    method_performance[method_name]['errors'].append(error)
                    method_performance[method_name]['contributions'].append(
                        method_result.get('growth', 0)
                    )

            # è¨ˆç®—å„æ–¹æ³•çš„å¹³å‡è¡¨ç¾
            method_scores = {}
            for method_name, data in method_performance.items():
                if data['errors']:
                    avg_error = np.mean(data['errors'])
                    error_std = np.std(data['errors'])

                    # è¨ˆç®—æ–¹æ³•åˆ†æ•¸ (èª¤å·®è¶Šä½åˆ†æ•¸è¶Šé«˜)
                    score = max(0, 1 - (avg_error / 100))  # å°‡MAPEè½‰æ›ç‚ºåˆ†æ•¸

                    method_scores[method_name] = {
                        'score': score,
                        'avg_error': avg_error,
                        'error_std': error_std,
                        'suggested_weight_adjustment': self._calculate_weight_adjustment(score)
                    }

            return method_scores

        except Exception as e:
            logger.warning(f"Failed to analyze method performance: {e}")
            return {}

    def _calculate_weight_adjustment(self, score: float) -> float:
        """è¨ˆç®—æ¬Šé‡èª¿æ•´å»ºè­°"""
        # åŸºæ–¼åˆ†æ•¸èª¿æ•´æ¬Šé‡
        if score > 0.8:
            return 1.1  # å¢åŠ 10%æ¬Šé‡
        elif score > 0.6:
            return 1.0  # ç¶­æŒæ¬Šé‡
        elif score > 0.4:
            return 0.9  # æ¸›å°‘10%æ¬Šé‡
        else:
            return 0.8  # æ¸›å°‘20%æ¬Šé‡

    def _prepare_hyperparameter_tuning_data(self, stock_id: str) -> Optional[Tuple]:
        """æº–å‚™è¶…åƒæ•¸èª¿æ•´çš„è¨“ç·´è³‡æ–™"""
        try:
            # ç²å–è‚¡ç¥¨çš„æ­·å²è³‡æ–™
            comprehensive_data = self.db_manager.get_comprehensive_data(stock_id)

            if comprehensive_data['data_quality']['overall_score'] < 0.5:
                return None

            # æå–ç‰¹å¾µ (ä½¿ç”¨AIæ¨¡å‹çš„ç‰¹å¾µæå–æ–¹æ³•)
            features = self.ai_model._extract_features(stock_id)
            if features is None:
                return None

            # è¨ˆç®—æ­·å²é æ¸¬èª¤å·®ä½œç‚ºç›®æ¨™è®Šæ•¸
            target = self.ai_model._calculate_historical_error(comprehensive_data)
            if target is None:
                return None

            # å‰µå»ºè¨“ç·´è³‡æ–™
            X = np.array([features])
            y = np.array([target])

            return X, y

        except Exception as e:
            logger.warning(f"Failed to prepare hyperparameter tuning data: {e}")
            return None

    def _generate_optimization_recommendations(self, analysis: Dict) -> List[str]:
        """ç”Ÿæˆå„ªåŒ–å»ºè­°"""
        recommendations = []

        try:
            problem_areas = analysis.get('problem_areas', [])
            revenue_perf = analysis.get('revenue_performance', {})
            eps_perf = analysis.get('eps_performance', {})

            # åŸºæ–¼å•é¡Œå€åŸŸç”Ÿæˆå»ºè­°
            if 'revenue_direction_accuracy' in problem_areas:
                recommendations.append(
                    f"ç‡Ÿæ”¶æ–¹å‘é æ¸¬æº–ç¢ºåº¦åä½ ({revenue_perf.get('direction_accuracy', 0):.1%})ï¼Œ"
                    "å»ºè­°é‡æ–°è¨“ç·´AIæ¨¡å‹æˆ–å¢åŠ æ›´å¤šæ­·å²è³‡æ–™"
                )

            if 'eps_direction_accuracy' in problem_areas:
                recommendations.append(
                    f"EPSæ–¹å‘é æ¸¬æº–ç¢ºåº¦åä½ ({eps_perf.get('direction_accuracy', 0):.1%})ï¼Œ"
                    "å»ºè­°æª¢æŸ¥EPSé æ¸¬æ–¹æ³•çš„æ¬Šé‡é…ç½®"
                )

            if 'revenue_magnitude_error' in problem_areas:
                recommendations.append(
                    f"ç‡Ÿæ”¶å¹…åº¦èª¤å·®è¼ƒå¤§ (MAPE: {revenue_perf.get('mape', 0):.1f}%)ï¼Œ"
                    "å»ºè­°èª¿æ•´è²¡å‹™å…¬å¼çš„æ¬Šé‡åˆ†é…"
                )

            if 'eps_magnitude_error' in problem_areas:
                recommendations.append(
                    f"EPSå¹…åº¦èª¤å·®è¼ƒå¤§ (MAPE: {eps_perf.get('mape', 0):.1f}%)ï¼Œ"
                    "å»ºè­°å„ªåŒ–åˆ©æ½¤ç‡åˆ†ææ–¹æ³•"
                )

            # æ•´é«”å»ºè­°
            overall_assessment = analysis.get('overall_assessment', {})
            if overall_assessment.get('needs_optimization', False):
                recommendations.append(
                    "æ•´é«”é æ¸¬è¡¨ç¾éœ€è¦æ”¹å–„ï¼Œå»ºè­°è€ƒæ…®è¨“ç·´è‚¡ç¥¨å°ˆç”¨AIæ¨¡å‹"
                )

            # è³‡æ–™å“è³ªå»ºè­°
            revenue_periods = revenue_perf.get('periods_tested', 0)
            eps_periods = eps_perf.get('periods_tested', 0)

            if revenue_periods < 6:
                recommendations.append("ç‡Ÿæ”¶å›æ¸¬æœŸæ•¸ä¸è¶³ï¼Œå»ºè­°å¢åŠ æ›´å¤šæ­·å²è³‡æ–™ä»¥æé«˜æ¨¡å‹ç©©å®šæ€§")

            if eps_periods < 4:
                recommendations.append("EPSå›æ¸¬æœŸæ•¸ä¸è¶³ï¼Œå»ºè­°å¢åŠ æ›´å¤šå­£åº¦è²¡å‹™è³‡æ–™")

            if not recommendations:
                recommendations.append("æ¨¡å‹è¡¨ç¾è‰¯å¥½ï¼Œå»ºè­°æŒçºŒç›£æ§ä¸¦å®šæœŸé€²è¡Œå›æ¸¬é©—è­‰")

            return recommendations

        except Exception as e:
            logger.warning(f"Failed to generate optimization recommendations: {e}")
            return ["ç„¡æ³•ç”Ÿæˆå„ªåŒ–å»ºè­°ï¼Œè«‹æª¢æŸ¥åˆ†æçµæœ"]

    def _save_optimization_history(self, optimization_result: Dict) -> None:
        """ä¿å­˜å„ªåŒ–æ­·å²"""
        try:
            # è®€å–ç¾æœ‰æ­·å²
            history = []
            if self.optimization_history_path.exists():
                with open(self.optimization_history_path, 'r', encoding='utf-8') as f:
                    history = json.load(f)

            # æ·»åŠ æ–°è¨˜éŒ„
            history.append(optimization_result)

            # ä¿æŒæœ€è¿‘100æ¢è¨˜éŒ„
            if len(history) > 100:
                history = history[-100:]

            # ä¿å­˜æ›´æ–°çš„æ­·å²
            with open(self.optimization_history_path, 'w', encoding='utf-8') as f:
                json.dump(history, f, ensure_ascii=False, indent=2)

            logger.info(f"Optimization history saved for {optimization_result.get('stock_id')}")

        except Exception as e:
            logger.warning(f"Failed to save optimization history: {e}")

    def get_optimization_history(self, stock_id: str = None) -> List[Dict]:
        """ç²å–å„ªåŒ–æ­·å²"""
        try:
            if not self.optimization_history_path.exists():
                return []

            with open(self.optimization_history_path, 'r', encoding='utf-8') as f:
                history = json.load(f)

            if stock_id:
                # éæ¿¾ç‰¹å®šè‚¡ç¥¨çš„æ­·å²
                history = [h for h in history if h.get('stock_id') == stock_id]

            return history

        except Exception as e:
            logger.warning(f"Failed to get optimization history: {e}")
            return []

    def display_optimization_summary(self, optimization_result: Dict) -> None:
        """é¡¯ç¤ºå„ªåŒ–æ‘˜è¦"""
        try:
            stock_id = optimization_result.get('stock_id', 'Unknown')
            optimization_time = optimization_result.get('optimization_time', 'Unknown')

            print(f"\n{'='*60}")
            print(f"ğŸ”§ {stock_id} AIæ¨¡å‹å„ªåŒ–çµæœ")
            print(f"{'='*60}")
            print(f"â° å„ªåŒ–æ™‚é–“: {optimization_time}")

            # é¡¯ç¤ºæ‡‰ç”¨çš„å„ªåŒ–ç­–ç•¥
            optimizations = optimization_result.get('optimizations_applied', [])
            if optimizations:
                print(f"\nğŸ¯ å·²æ‡‰ç”¨çš„å„ªåŒ–ç­–ç•¥:")
                for i, opt in enumerate(optimizations, 1):
                    strategy = opt.get('strategy', 'Unknown')
                    success = opt.get('success', False)
                    status = "âœ… æˆåŠŸ" if success else "âŒ å¤±æ•—"
                    print(f"   {i}. {strategy}: {status}")

                    if success and 'improvement_expected' in opt:
                        print(f"      é æœŸæ”¹å–„: {opt['improvement_expected']}")
                    elif not success and 'error' in opt:
                        print(f"      éŒ¯èª¤: {opt['error']}")

            # é¡¯ç¤ºå»ºè­°
            recommendations = optimization_result.get('recommendations', [])
            if recommendations:
                print(f"\nğŸ’¡ å„ªåŒ–å»ºè­°:")
                for i, rec in enumerate(recommendations, 1):
                    print(f"   {i}. {rec}")

            print(f"\n{'='*60}")

        except Exception as e:
            logger.error(f"Failed to display optimization summary: {e}")
            print(f"âŒ ç„¡æ³•é¡¯ç¤ºå„ªåŒ–æ‘˜è¦: {e}")
