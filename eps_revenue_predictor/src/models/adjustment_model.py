# -*- coding: utf-8 -*-
"""
EPS Revenue Predictor - AI Adjustment Model
å°ˆç”¨å‹AIèª¿æ•´æ¨¡å‹ (20%æ¬Šé‡)
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

try:
    from lightgbm import LGBMRegressor
    LIGHTGBM_AVAILABLE = True
except ImportError:
    from sklearn.ensemble import GradientBoostingRegressor
    LIGHTGBM_AVAILABLE = False

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import joblib
from pathlib import Path

from config.settings import AI_MODEL_CONFIG, PROJECT_ROOT
from src.data.database_manager import DatabaseManager
from src.utils.logger import get_logger, log_execution

logger = get_logger('adjustment_model')

class AIAdjustmentModel:
    """å°ˆç”¨å‹AIèª¿æ•´æ¨¡å‹
    
    ç”¨æ–¼å°è²¡å‹™å…¬å¼é æ¸¬çµæœé€²è¡Œæ™ºèƒ½èª¿æ•´
    èª¿æ•´ç¯„åœé™åˆ¶åœ¨Â±20%ä»¥å…§
    """
    
    def __init__(self, db_manager: DatabaseManager = None):
        self.db_manager = db_manager or DatabaseManager()
        self.config = AI_MODEL_CONFIG
        self.model = None
        self.scaler = StandardScaler()
        self.is_trained = False
        self.model_path = PROJECT_ROOT / 'models' / 'adjustment_model.pkl'
        self.scaler_path = PROJECT_ROOT / 'models' / 'adjustment_scaler.pkl'
        
        # ç¢ºä¿æ¨¡å‹ç›®éŒ„å­˜åœ¨
        self.model_path.parent.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"AIAdjustmentModel initialized (LightGBM: {LIGHTGBM_AVAILABLE})")
    
    @log_execution
    def train_model(self, stock_list: List[str] = None, retrain: bool = False) -> Dict:
        """
        è¨“ç·´èª¿æ•´æ¨¡å‹
        
        Args:
            stock_list: è¨“ç·´ç”¨è‚¡ç¥¨åˆ—è¡¨
            retrain: æ˜¯å¦å¼·åˆ¶é‡æ–°è¨“ç·´
            
        Returns:
            è¨“ç·´çµæœ
        """
        # æª¢æŸ¥æ˜¯å¦éœ€è¦è¨“ç·´
        if not retrain and self._load_existing_model():
            logger.info("Loaded existing trained model")
            return {'status': 'loaded_existing', 'model_exists': True}
        
        logger.info("Starting AI adjustment model training")
        
        # ç²å–è¨“ç·´è‚¡ç¥¨åˆ—è¡¨
        if stock_list is None:
            stock_list = self.db_manager.get_available_stocks(limit=50)  # é™åˆ¶50æª”è‚¡ç¥¨
        
        # æ”¶é›†è¨“ç·´è³‡æ–™
        training_data = self._collect_training_data(stock_list)
        
        if training_data.empty:
            logger.error("No training data available")
            return {'status': 'failed', 'reason': 'no_data'}
        
        # æº–å‚™ç‰¹å¾µå’Œç›®æ¨™è®Šæ•¸
        X, y = self._prepare_training_data(training_data)
        
        if len(X) < 10:
            logger.warning(f"Insufficient training samples: {len(X)}")
            return {'status': 'failed', 'reason': 'insufficient_samples'}
        
        # åˆ†å‰²è¨“ç·´å’Œé©—è­‰é›†
        X_train, X_val, y_train, y_val = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # æ¨™æº–åŒ–ç‰¹å¾µ
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_val_scaled = self.scaler.transform(X_val)
        
        # è¨“ç·´æ¨¡å‹
        self.model = self._create_model()
        self.model.fit(X_train_scaled, y_train)
        
        # è©•ä¼°æ¨¡å‹
        train_score = self.model.score(X_train_scaled, y_train)
        val_score = self.model.score(X_val_scaled, y_val)
        
        # é æ¸¬é©—è­‰é›†
        y_pred = self.model.predict(X_val_scaled)
        mae = np.mean(np.abs(y_val - y_pred))
        rmse = np.sqrt(np.mean((y_val - y_pred) ** 2))
        
        self.is_trained = True
        
        # ä¿å­˜æ¨¡å‹
        self._save_model()
        
        training_result = {
            'status': 'success',
            'training_samples': len(X_train),
            'validation_samples': len(X_val),
            'train_r2': train_score,
            'validation_r2': val_score,
            'mae': mae,
            'rmse': rmse,
            'features_used': self.config['features']
        }
        
        logger.log_model_training('AI_Adjustment', len(X_train), training_result)
        
        return training_result

    def train_stock_specific_model(self, stock_id: str, max_date: datetime = None) -> Dict:
        """
        è¨“ç·´è‚¡ç¥¨å°ˆç”¨AIæ¨¡å‹ (ç”¨æ–¼å›æ¸¬)

        Args:
            stock_id: è‚¡ç¥¨ä»£ç¢¼
            max_date: æœ€å¤§è³‡æ–™æ—¥æœŸé™åˆ¶ (ç”¨æ–¼å›æ¸¬)

        Returns:
            è¨“ç·´çµæœ
        """
        logger.info(f"[STOCK_SPECIFIC_TRAINING] Training stock-specific model | "
                   f"stock_id={stock_id} | max_date={max_date}")

        try:
            # ğŸ”§ æ”¶é›†è©²è‚¡ç¥¨çš„æ­·å²è¨“ç·´è³‡æ–™ (é™åˆ¶æ™‚é–“ç¯„åœ)
            training_data = self._collect_stock_specific_training_data(stock_id, max_date)

            if training_data.empty or len(training_data) < 5:
                logger.warning(f"Insufficient stock-specific training data: {len(training_data)} samples")
                # å¦‚æœå°ˆç”¨è³‡æ–™ä¸è¶³ï¼Œä½¿ç”¨é€šç”¨æ¨¡å‹
                return {'status': 'fallback_to_general', 'samples': len(training_data)}

            # æº–å‚™ç‰¹å¾µå’Œç›®æ¨™è®Šæ•¸
            X, y = self._prepare_training_data(training_data)

            if len(X) < 3:
                logger.warning(f"Insufficient training samples after preparation: {len(X)}")
                return {'status': 'fallback_to_general', 'samples': len(X)}

            # ğŸ¤– å‰µå»ºä¸¦è¨“ç·´å°ˆç”¨æ¨¡å‹
            stock_specific_model = self._create_model()

            # å¦‚æœæ¨£æœ¬å¤ªå°‘ï¼Œä½¿ç”¨ç°¡å–®çš„ç·šæ€§å›æ­¸
            if len(X) < 10:
                from sklearn.linear_model import LinearRegression
                stock_specific_model = LinearRegression()

            # æ¨™æº–åŒ–ç‰¹å¾µ (ä½¿ç”¨å°ˆç”¨çš„scaler)
            stock_scaler = StandardScaler()
            X_scaled = stock_scaler.fit_transform(X)

            # è¨“ç·´å°ˆç”¨æ¨¡å‹
            stock_specific_model.fit(X_scaled, y)

            # è©•ä¼°æ¨¡å‹
            train_score = stock_specific_model.score(X_scaled, y)
            y_pred = stock_specific_model.predict(X_scaled)
            mae = np.mean(np.abs(y - y_pred))
            rmse = np.sqrt(np.mean((y - y_pred) ** 2))

            # ğŸ”§ æ›¿æ›ç•¶å‰æ¨¡å‹ç‚ºå°ˆç”¨æ¨¡å‹ (è‡¨æ™‚)
            self.model = stock_specific_model
            self.scaler = stock_scaler
            self.is_trained = True

            training_result = {
                'status': 'success',
                'model_type': 'stock_specific',
                'training_samples': len(X),
                'train_r2': train_score,
                'mae': mae,
                'rmse': rmse,
                'data_range': {
                    'start_date': training_data['date'].min().strftime('%Y-%m-%d') if 'date' in training_data.columns else None,
                    'end_date': training_data['date'].max().strftime('%Y-%m-%d') if 'date' in training_data.columns else None
                }
            }

            logger.info(f"[STOCK_SPECIFIC_TRAINING] Stock-specific model trained successfully | "
                       f"samples={len(X)} | r2={train_score:.3f} | mae={mae:.3f}")

            return training_result

        except Exception as e:
            logger.error(f"Stock-specific model training failed: {e}")
            return {'status': 'failed', 'error': str(e)}

    def _calculate_features_for_stock(self, monthly_data: pd.DataFrame,
                                    financial_data: pd.DataFrame,
                                    current_date: datetime) -> Dict:
        """ç‚ºå–®ä¸€è‚¡ç¥¨è¨ˆç®—ç‰¹å¾µ"""
        try:
            features = {}

            if len(monthly_data) >= 3:
                # ç‡Ÿæ”¶ç›¸é—œç‰¹å¾µ
                recent_revenues = monthly_data['revenue'].tail(3).values
                features['revenue_trend'] = (recent_revenues[-1] - recent_revenues[0]) / recent_revenues[0]
                features['revenue_volatility'] = np.std(recent_revenues) / np.mean(recent_revenues)

                # æˆé•·ç‡ç‰¹å¾µ
                if len(monthly_data) >= 12:
                    yoy_growth = monthly_data['revenue_growth_yoy'].tail(3).mean()
                    features['avg_yoy_growth'] = yoy_growth if not pd.isna(yoy_growth) else 0
                else:
                    features['avg_yoy_growth'] = 0

                # å­£ç¯€æ€§ç‰¹å¾µ
                month = current_date.month
                features['month'] = month
                features['quarter'] = (month - 1) // 3 + 1
            else:
                # é è¨­å€¼
                features['revenue_trend'] = 0
                features['revenue_volatility'] = 0
                features['avg_yoy_growth'] = 0
                features['month'] = current_date.month
                features['quarter'] = (current_date.month - 1) // 3 + 1

            # è²¡å‹™æ¯”ç‡ç‰¹å¾µ (å¦‚æœæœ‰çš„è©±)
            if not financial_data.empty:
                latest_financial = financial_data.iloc[-1]
                features['roe'] = latest_financial.get('roe', 0) or 0
                features['roa'] = latest_financial.get('roa', 0) or 0
            else:
                features['roe'] = 0
                features['roa'] = 0

            return features

        except Exception as e:
            logger.warning(f"Feature calculation failed: {e}")
            return {
                'revenue_trend': 0,
                'revenue_volatility': 0,
                'avg_yoy_growth': 0,
                'month': current_date.month,
                'quarter': (current_date.month - 1) // 3 + 1,
                'roe': 0,
                'roa': 0
            }

    def _collect_stock_specific_training_data(self, stock_id: str, max_date: datetime = None) -> pd.DataFrame:
        """æ”¶é›†è‚¡ç¥¨å°ˆç”¨è¨“ç·´è³‡æ–™"""
        try:
            # ç²å–è©²è‚¡ç¥¨çš„æ­·å²è³‡æ–™ (é™åˆ¶æ™‚é–“ç¯„åœ)
            if max_date:
                # ä½¿ç”¨æ­·å²è³‡æ–™æŸ¥è©¢
                comprehensive_data = self.db_manager.get_comprehensive_data_historical(
                    stock_id, max_date=max_date
                )
            else:
                comprehensive_data = self.db_manager.get_comprehensive_data(stock_id)

            if not comprehensive_data or comprehensive_data.get('monthly_revenue', pd.DataFrame()).empty:
                return pd.DataFrame()

            # æ§‹å»ºè¨“ç·´è³‡æ–™
            monthly_data = comprehensive_data.get('monthly_revenue', pd.DataFrame())
            financial_data = comprehensive_data.get('financial_data', pd.DataFrame())

            # åˆä½µè³‡æ–™ä¸¦è¨ˆç®—ç‰¹å¾µ
            training_records = []

            for i in range(1, len(monthly_data)):
                current_month = monthly_data.iloc[i]
                prev_month = monthly_data.iloc[i-1]

                # è¨ˆç®—å¯¦éš›æˆé•·ç‡ (ç›®æ¨™è®Šæ•¸)
                actual_growth = (current_month['revenue'] - prev_month['revenue']) / prev_month['revenue']

                # è¨ˆç®—ç‰¹å¾µ
                features = self._calculate_features_for_stock(
                    monthly_data.iloc[:i], financial_data, current_month['date']
                )

                if features:
                    record = features.copy()
                    record['actual_growth'] = actual_growth
                    record['date'] = current_month['date']
                    training_records.append(record)

            if training_records:
                training_df = pd.DataFrame(training_records)
                logger.info(f"Collected {len(training_df)} stock-specific training records for {stock_id}")
                return training_df

            return pd.DataFrame()

        except Exception as e:
            logger.error(f"Failed to collect stock-specific training data: {e}")
            return pd.DataFrame()

    @log_execution
    def predict_adjustment_factor(self, stock_id: str, base_prediction: float,
                                prediction_type: str = 'revenue') -> Dict:
        """
        é æ¸¬èª¿æ•´å› å­
        
        Args:
            stock_id: è‚¡ç¥¨ä»£ç¢¼
            base_prediction: åŸºç¤é æ¸¬å€¼
            prediction_type: é æ¸¬é¡å‹ ('revenue' æˆ– 'eps')
            
        Returns:
            èª¿æ•´çµæœ
        """
        if not self.is_trained and not self._load_existing_model():
            logger.warning("Model not trained, returning zero adjustment")
            return {
                'adjustment_factor': 0.0,
                'adjusted_prediction': base_prediction,
                'confidence': 'Low',
                'reason': 'model_not_trained'
            }
        
        try:
            # æå–ç‰¹å¾µ
            features = self._extract_features(stock_id)
            
            if features is None:
                return {
                    'adjustment_factor': 0.0,
                    'adjusted_prediction': base_prediction,
                    'confidence': 'Low',
                    'reason': 'feature_extraction_failed'
                }
            
            # æ¨™æº–åŒ–ç‰¹å¾µ
            features_scaled = self.scaler.transform([features])
            
            # é æ¸¬èª¿æ•´å› å­
            raw_adjustment = self.model.predict(features_scaled)[0]
            
            # é™åˆ¶èª¿æ•´ç¯„åœåœ¨Â±20%ä»¥å…§
            max_adjustment = self.config['adjustment_range']
            adjustment_factor = np.clip(raw_adjustment, -max_adjustment, max_adjustment)
            
            # è¨ˆç®—èª¿æ•´å¾Œçš„é æ¸¬å€¼
            adjusted_prediction = base_prediction * (1 + adjustment_factor)
            
            # è©•ä¼°èª¿æ•´ä¿¡å¿ƒåº¦
            confidence = self._evaluate_adjustment_confidence(features, adjustment_factor)
            
            result = {
                'adjustment_factor': adjustment_factor,
                'adjusted_prediction': adjusted_prediction,
                'raw_adjustment': raw_adjustment,
                'confidence': confidence,
                'features_used': dict(zip(self.config['features'], features)),
                'base_prediction': base_prediction
            }
            
            logger.debug(f"AI adjustment for {stock_id}: {adjustment_factor:.3f} ({confidence})")
            
            return result
            
        except Exception as e:
            logger.error(f"AI adjustment prediction failed: {e}", stock_id=stock_id)
            return {
                'adjustment_factor': 0.0,
                'adjusted_prediction': base_prediction,
                'confidence': 'Low',
                'reason': f'prediction_error: {str(e)}'
            }
    
    def _create_model(self):
        """å‰µå»ºæ©Ÿå™¨å­¸ç¿’æ¨¡å‹"""
        if LIGHTGBM_AVAILABLE:
            return LGBMRegressor(
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1,
                random_state=42,
                verbose=-1
            )
        else:
            return GradientBoostingRegressor(
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1,
                random_state=42
            )
    
    def _collect_training_data(self, stock_list: List[str]) -> pd.DataFrame:
        """æ”¶é›†è¨“ç·´è³‡æ–™"""
        logger.info(f"Collecting training data for {len(stock_list)} stocks")
        
        training_records = []
        
        for stock_id in stock_list[:20]:  # é™åˆ¶20æª”è‚¡ç¥¨ä»¥åŠ å¿«è¨“ç·´
            try:
                # ç²å–è‚¡ç¥¨è³‡æ–™
                data = self.db_manager.get_comprehensive_data(stock_id)
                
                if data['data_quality']['overall_score'] < 0.5:
                    continue
                
                # æå–ç‰¹å¾µå’Œç›®æ¨™è®Šæ•¸
                features = self._extract_features(stock_id)
                if features is None:
                    continue
                
                # è¨ˆç®—æ­·å²é æ¸¬èª¤å·®ä½œç‚ºç›®æ¨™è®Šæ•¸
                target = self._calculate_historical_error(data)
                if target is None:
                    continue
                
                record = {
                    'stock_id': stock_id,
                    'target': target,
                    **dict(zip(self.config['features'], features))
                }
                
                training_records.append(record)
                
            except Exception as e:
                logger.warning(f"Failed to process stock {stock_id}: {e}")
                continue
        
        df = pd.DataFrame(training_records)
        logger.info(f"Collected {len(df)} training records")
        
        return df
    
    def _extract_features(self, stock_id: str) -> Optional[List[float]]:
        """æå–èª¿æ•´æ¨¡å‹ç‰¹å¾µ"""
        try:
            data = self.db_manager.get_comprehensive_data(stock_id)
            
            if data['data_quality']['overall_score'] < 0.3:
                return None
            
            features = []
            
            # ç‰¹å¾µ1: ç‡Ÿæ”¶æ³¢å‹•æ€§
            revenue_data = data['monthly_revenue']
            if not revenue_data.empty:
                revenue_volatility = revenue_data['revenue'].std() / revenue_data['revenue'].mean()
                features.append(revenue_volatility)
            else:
                features.append(0.5)  # é è¨­å€¼
            
            # ç‰¹å¾µ2: åˆ©æ½¤ç‡è¶¨å‹¢
            ratio_data = data['financial_ratios']
            if not ratio_data.empty and 'net_margin' in ratio_data.columns:
                margin_trend = self._calculate_trend(ratio_data['net_margin'])
                features.append(margin_trend)
            else:
                features.append(0.0)
            
            # ç‰¹å¾µ3: ç‡Ÿæ¥­è²»ç”¨æ•ˆç‡
            if not ratio_data.empty and 'operating_margin' in ratio_data.columns and 'gross_margin' in ratio_data.columns:
                opex_efficiency = self._calculate_opex_efficiency(ratio_data)
                features.append(opex_efficiency)
            else:
                features.append(0.0)
            
            # ç‰¹å¾µ4: ç”¢æ¥­å‹•èƒ½ (ç°¡åŒ–ç‰ˆ)
            industry_momentum = self._estimate_industry_momentum(stock_id)
            features.append(industry_momentum)
            
            # ç‰¹å¾µ5: å¸‚å ´æƒ…ç·’ (ç°¡åŒ–ç‰ˆ)
            market_sentiment = self._estimate_market_sentiment()
            features.append(market_sentiment)
            
            return features
            
        except Exception as e:
            logger.error(f"Feature extraction failed for {stock_id}: {e}")
            return None
    
    def _calculate_trend(self, series: pd.Series) -> float:
        """è¨ˆç®—æ™‚é–“åºåˆ—è¶¨å‹¢"""
        if len(series) < 3:
            return 0.0
        
        clean_series = series.dropna()
        if len(clean_series) < 3:
            return 0.0
        
        x = np.arange(len(clean_series))
        y = clean_series.values
        
        try:
            coeffs = np.polyfit(x, y, 1)
            return coeffs[0] / (np.mean(y) + 0.01)  # æ¨™æº–åŒ–è¶¨å‹¢
        except:
            return 0.0
    
    def _calculate_opex_efficiency(self, ratio_data: pd.DataFrame) -> float:
        """è¨ˆç®—ç‡Ÿæ¥­è²»ç”¨æ•ˆç‡"""
        if 'gross_margin' not in ratio_data.columns or 'operating_margin' not in ratio_data.columns:
            return 0.0
        
        opex_ratio = ratio_data['gross_margin'] - ratio_data['operating_margin']
        return -self._calculate_trend(opex_ratio)  # ç‡Ÿæ¥­è²»ç”¨ç‡ä¸‹é™æ˜¯å¥½äº‹
    
    def _estimate_industry_momentum(self, stock_id: str) -> float:
        """ä¼°ç®—ç”¢æ¥­å‹•èƒ½ (ç°¡åŒ–ç‰ˆ)"""
        # é€™è£¡å¯ä»¥å¯¦ä½œæ›´è¤‡é›œçš„ç”¢æ¥­åˆ†æ
        # ç›®å‰è¿”å›éš¨æ©Ÿå€¼ä½œç‚ºä½”ä½ç¬¦
        np.random.seed(hash(stock_id) % 2**32)
        return np.random.normal(0, 0.1)
    
    def _estimate_market_sentiment(self) -> float:
        """ä¼°ç®—å¸‚å ´æƒ…ç·’ (ç°¡åŒ–ç‰ˆ)"""
        # é€™è£¡å¯ä»¥å¯¦ä½œå¸‚å ´æƒ…ç·’åˆ†æ
        # ç›®å‰è¿”å›å›ºå®šå€¼
        return 0.0
    
    def _calculate_historical_error(self, data: Dict) -> Optional[float]:
        """è¨ˆç®—æ­·å²é æ¸¬èª¤å·®ä½œç‚ºè¨“ç·´ç›®æ¨™"""
        # ç°¡åŒ–ç‰ˆï¼šä½¿ç”¨ç‡Ÿæ”¶æ³¢å‹•æ€§ä½œç‚ºä»£ç†è®Šæ•¸
        revenue_data = data['monthly_revenue']
        if revenue_data.empty or len(revenue_data) < 6:
            return None
        
        # è¨ˆç®—é æ¸¬èª¤å·®çš„ä»£ç†æŒ‡æ¨™
        recent_volatility = revenue_data['revenue'].tail(6).std() / revenue_data['revenue'].tail(6).mean()
        overall_volatility = revenue_data['revenue'].std() / revenue_data['revenue'].mean()
        
        # èª¤å·®ä»£ç† = è¿‘æœŸæ³¢å‹•æ€§ - æ•´é«”æ³¢å‹•æ€§
        error_proxy = recent_volatility - overall_volatility
        
        # é™åˆ¶åœ¨åˆç†ç¯„åœå…§
        return np.clip(error_proxy, -0.2, 0.2)
    
    def _prepare_training_data(self, training_data: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        """æº–å‚™è¨“ç·´è³‡æ–™"""
        feature_cols = self.config['features']
        
        X = training_data[feature_cols].values
        y = training_data['target'].values
        
        # ç§»é™¤ç•°å¸¸å€¼
        mask = (np.abs(y) < 0.5) & np.isfinite(X).all(axis=1) & np.isfinite(y)
        X = X[mask]
        y = y[mask]
        
        return X, y
    
    def _evaluate_adjustment_confidence(self, features: List[float], adjustment: float) -> str:
        """è©•ä¼°èª¿æ•´ä¿¡å¿ƒåº¦"""
        # åŸºæ–¼ç‰¹å¾µå“è³ªå’Œèª¿æ•´å¹…åº¦è©•ä¼°ä¿¡å¿ƒåº¦
        feature_quality = 1 - np.mean([abs(f) for f in features if abs(f) < 10])  # é¿å…æ¥µç«¯å€¼
        adjustment_magnitude = abs(adjustment)
        
        if feature_quality > 0.7 and adjustment_magnitude < 0.1:
            return 'High'
        elif feature_quality > 0.5 and adjustment_magnitude < 0.15:
            return 'Medium'
        else:
            return 'Low'
    
    def _save_model(self):
        """ä¿å­˜æ¨¡å‹"""
        try:
            joblib.dump(self.model, self.model_path)
            joblib.dump(self.scaler, self.scaler_path)
            logger.info(f"Model saved to {self.model_path}")
        except Exception as e:
            logger.error(f"Failed to save model: {e}")
    
    def _load_existing_model(self) -> bool:
        """è¼‰å…¥ç¾æœ‰æ¨¡å‹"""
        try:
            if self.model_path.exists() and self.scaler_path.exists():
                self.model = joblib.load(self.model_path)
                self.scaler = joblib.load(self.scaler_path)
                self.is_trained = True
                logger.info("Existing model loaded successfully")
                return True
        except Exception as e:
            logger.warning(f"Failed to load existing model: {e}")
        
        return False

if __name__ == "__main__":
    # æ¸¬è©¦AIèª¿æ•´æ¨¡å‹
    model = AIAdjustmentModel()
    
    print("Testing AI Adjustment Model")
    
    # è¨“ç·´æ¨¡å‹
    print("Training model...")
    train_result = model.train_model(retrain=True)
    print(f"Training result: {train_result['status']}")
    
    if train_result['status'] == 'success':
        # æ¸¬è©¦é æ¸¬
        test_stock = "2385"
        base_prediction = 0.15  # 15%æˆé•·ç‡
        
        adjustment_result = model.predict_adjustment_factor(test_stock, base_prediction)
        
        print(f"Base prediction: {base_prediction:.2%}")
        print(f"Adjustment factor: {adjustment_result['adjustment_factor']:.3f}")
        print(f"Adjusted prediction: {adjustment_result['adjusted_prediction']:.2%}")
        print(f"Confidence: {adjustment_result['confidence']}")
